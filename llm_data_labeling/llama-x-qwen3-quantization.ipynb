{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import accelerate\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"your token\"\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# posts_llama_2000 = pd.read_csv(\"/kaggle/input/data-for-llama-labeling/data_llama_raw.csv\")\n",
    "posts_llama_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "max_memory_map = {\n",
    "    0: \"14GiB\", \n",
    "    1: \"14GiB\"\n",
    "}\n",
    "\n",
    "print(\"Загрузка токенизатора...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, legacy=False)\n",
    "\n",
    "print(\"Загрузка модели с device_map='auto' и max_memory...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    max_memory=max_memory_map,\n",
    ")\n",
    "clear_output()\n",
    "print(\"Модель загружена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Ты - ИИ для анализа финансового сентимента постов.\n",
    "Твоя задача - классифицировать пост по его тональности относительно торговли акциями.\n",
    "Верни ТОЛЬКО ОДНО ЧИСЛО: 1 (покупка/бычий), 0 (нейтральный), -1 (продажа/медвежий). Без пояснений.\n",
    "\n",
    "Вот примеры:\n",
    "\n",
    "Пост: \"Отличный отчет! Ракета готова к взлету, закупаюсь на всю котлету #SBER\"\n",
    "Ответ: 1\n",
    "Пост: \"Фиксанул прибыль по $GAZP. Рынок выглядит перегретым, возможна коррекция.\"\n",
    "Ответ: -1\n",
    "Пост: \"Сегодня ВТБ опубликует финансовые результаты за квартал. Интересно посмотреть.\"\n",
    "Ответ: 0\n",
    "Пост: \"Что думаете про $SBER? Вроде и дивы хорошие, но геополитика давит...\"\n",
    "Ответ: 0\n",
    "Пост: \"Зашортил сбер перед отчетом\"\n",
    "Ответ: -1\n",
    "Пост: \"пора докупать сбербанк пока дешевый\"\n",
    "Ответ: 1\n",
    "Пост: \"какие прогнозы по втб?\"\n",
    "Ответ: 0\n",
    "\n",
    "Теперь твоя задача: проанализируй следующий пост и верни ТОЛЬКО число.\n",
    "\"\"\"\n",
    "\n",
    "# query = \"пора сливать это дерьмо\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "]\n",
    "\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\" # Возвращаем тензоры PyTorch\n",
    ")\n",
    "\n",
    "input_ids = input_ids.to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "print(f\"\\nЗапрос к модели:\\nSystem: {system_prompt}\\nUser: {query}\")\n",
    "print(\"\\nГенерация ответа...\")\n",
    "\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=20,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=False, \n",
    "    pad_token_id=tokenizer.eos_token_id \n",
    ")\n",
    "\n",
    "response_ids = outputs[0][input_ids.shape[1]:]\n",
    "response_text = tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "\n",
    "print(f\"\\nСгенерированный ответ модели (сырой):\")\n",
    "print(response_text)\n",
    "\n",
    "try:\n",
    "    sentiment_score = int(response_text.strip())\n",
    "    print(f\"\\nИзвлеченное значение сентимента: {sentiment_score}\")\n",
    "except ValueError:\n",
    "    print(f\"\\nНе удалось извлечь число из ответа: '{response_text.strip()}'\")\n",
    "    print(\"Возможно, модель сгенерировала дополнительный текст. Попробуйте настроить промпт или параметры генерации.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, query):\n",
    "    # Format input with system prompt and user query\n",
    "    prompt = f\"<|system|>\\n{system_prompt}\\n<|user|>\\n{query}\\n<|assistant|>\"\n",
    "    \n",
    "    # Generate response\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=10,  # Small value since we only need a single number\n",
    "        # temperature=0.1,    # Low temperature for consistent results\n",
    "        do_sample=False     # Deterministic generation\n",
    "    )\n",
    "    \n",
    "    # Decode the response, removing the input prompt\n",
    "    response = tokenizer.decode(output[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "    return response\n",
    "\n",
    "# Generate sentiment analysis result\n",
    "sentiment_result = generate_response(system_prompt, query)\n",
    "print(f\"Сентимент публикации: {sentiment_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{query}\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Генерация ответа...\")\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=10,  # Оставляем мало токенов для короткого ответа\n",
    "    # Опционально: параметры для улучшения качества генерации (можно раскомментировать и настроить)\n",
    "    # temperature=0.1,\n",
    "    # top_k=50,\n",
    "    # top_p=0.95,\n",
    "    # do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id # Явно указываем pad_token_id, если он есть\n",
    ")\n",
    "\n",
    "# 5. Декодируйте только сгенерированную часть ответа\n",
    "generated_token_ids = outputs[0][input_ids.shape[-1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.auto import tqdm \n",
    "import time # Для небольшой паузы и избежания перегрева/ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify_sentiment_llama(\n",
    "    df: pd.DataFrame,\n",
    "    model, # Тип: AutoModelForCausalLM\n",
    "    tokenizer, # Тип: AutoTokenizer\n",
    "    system_prompt: str,\n",
    "    text_column: str = \"processed_posts\",\n",
    "    output_column: str = \"llama_sentiment\",\n",
    "    max_new_tokens: int = 10,\n",
    "    default_sentiment: int = 0, # Значение по умолчанию при ошибке\n",
    "    batch_size: int = 1 # Обработка по одному посту (проще для начала)\n",
    "                       # Батчинг > 1 требует более сложной логики паддинга\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Классифицирует сентимент постов в DataFrame с помощью модели Llama.\n",
    "\n",
    "    Args:\n",
    "        df: Входной DataFrame.\n",
    "        model: Загруженная модель Llama (AutoModelForCausalLM).\n",
    "        tokenizer: Загруженный токенизатор Llama (AutoTokenizer).\n",
    "        system_prompt: Системный промпт для модели.\n",
    "        text_column: Имя колонки с текстом постов.\n",
    "        output_column: Имя новой колонки для сохранения результата.\n",
    "        max_new_tokens: Максимальное количество генерируемых токенов.\n",
    "        default_sentiment: Значение, присваиваемое в случае ошибки парсинга ответа.\n",
    "        batch_size: Размер батча (пока поддерживается только 1).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame с добавленной колонкой output_column.\n",
    "    \"\"\"\n",
    "    if batch_size != 1:\n",
    "        raise NotImplementedError(\"Batch size > 1 is not yet implemented in this function.\")\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # Определяем токены остановки один раз\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    # Итерация по постам с использованием tqdm для прогресс-бара\n",
    "    print(f\"Начинаем обработку {len(df)} постов...\")\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Классификация постов\"):\n",
    "        post_text = row[text_column]\n",
    "        \n",
    "        # Проверка на пустой или некорректный текст\n",
    "        if not isinstance(post_text, str) or not post_text.strip():\n",
    "            print(f\"Предупреждение: Пропущен пустой или некорректный пост с индексом {index}\")\n",
    "            results.append(default_sentiment)\n",
    "            continue\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": post_text}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # 1. Токенизация\n",
    "            input_ids = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device) # Сразу на устройство модели\n",
    "\n",
    "            # 2. Генерация\n",
    "            outputs = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                eos_token_id=terminators,\n",
    "                do_sample=False, # Важно для детерминированного вывода\n",
    "                pad_token_id=tokenizer.eos_token_id \n",
    "            )\n",
    "            \n",
    "            # 3. Декодирование только сгенерированной части\n",
    "            response_ids = outputs[0][input_ids.shape[1]:]\n",
    "            response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "            # 4. Попытка извлечь число\n",
    "            try:\n",
    "                sentiment_score = int(response_text)\n",
    "                # Опционально: проверка, что число в допустимом диапазоне\n",
    "                if sentiment_score not in [-1, 0, 1]:\n",
    "                     print(f\"Предупреждение: Модель вернула некорректное число {sentiment_score} для поста {index}. Ответ: '{response_text}'. Используется значение по умолчанию {default_sentiment}.\")\n",
    "                     results.append(default_sentiment)\n",
    "                else:\n",
    "                    results.append(sentiment_score)\n",
    "            except ValueError:\n",
    "                # Если модель вернула не число\n",
    "                print(f\"Предупреждение: Не удалось извлечь число из ответа для поста {index}. Ответ: '{response_text}'. Используется значение по умолчанию {default_sentiment}.\")\n",
    "                results.append(default_sentiment)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Обработка других ошибок (например, OOM при генерации)\n",
    "            print(f\"Ошибка при обработке поста {index}: {e}\")\n",
    "            print(f\"Текст поста: {post_text[:100]}...\") # Показать начало поста\n",
    "            results.append(default_sentiment) # Добавляем значение по умолчанию\n",
    "            # Можно добавить небольшую паузу, если ошибки связаны с перегрузкой\n",
    "            # time.sleep(1) \n",
    "\n",
    "    # Добавляем результаты как новую колонку\n",
    "    df[output_column] = results\n",
    "    print(\"Обработка завершена.\")\n",
    "    return df\n",
    "\n",
    "# --- Пример вызова функции ---\n",
    "# Убедитесь, что model и tokenizer загружены и posts_llama_2000 существует\n",
    "\n",
    "# Копируем DataFrame, чтобы не изменять оригинал (хорошая практика)\n",
    "df_processed = posts_llama_2000.copy() \n",
    "\n",
    "# Запускаем классификацию\n",
    "df_processed = classify_sentiment_llama(\n",
    "    df=df_processed,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=system_prompt,\n",
    "    text_column=\"processed_posts\", # Убедитесь, что имя колонки правильное\n",
    "    output_column=\"llama_3_1_sentiment\" # Новое имя колонки\n",
    ")\n",
    "\n",
    "# --- Проверка результатов ---\n",
    "print(\"\\nПример результатов:\")\n",
    "print(df_processed.head())\n",
    "\n",
    "print(\"\\nРаспределение полученных классов:\")\n",
    "print(df_processed['llama_3_1_sentiment'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import clear_output\n",
    "import time # Опционально, для проверки времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-14B\" \n",
    "# Указываем память, хотя модель должна поместиться и без offload\n",
    "max_memory_map = {\n",
    "    0: \"14GiB\", \n",
    "    1: \"14GiB\"\n",
    "    # \"cpu\": \"...\" # Можно добавить, но скорее всего не понадобится\n",
    "}\n",
    "\n",
    "# --- Загрузка ---\n",
    "print(f\"Загрузка токенизатора: {MODEL_NAME}\")\n",
    "# Добавляем trust_remote_code=True, т.к. модели Qwen могут его требовать\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
    "\n",
    "print(\"Загрузка модели...\")\n",
    "# Используем torch_dtype=\"auto\" для FP8\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\", # Рекомендовано для FP8\n",
    "    max_memory=max_memory_map,\n",
    "    trust_remote_code=True # Важно для Qwen\n",
    ")\n",
    "clear_output()\n",
    "print(\"Модель Qwen3-14B загружена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:24:25.522332Z",
     "iopub.status.busy": "2025-05-02T18:24:25.521593Z",
     "iopub.status.idle": "2025-05-02T18:24:25.526853Z",
     "shell.execute_reply": "2025-05-02T18:24:25.526008Z",
     "shell.execute_reply.started": "2025-05-02T18:24:25.522305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Ты - ИИ для анализа финансового сентимента постов.\n",
    "Твоя задача - классифицировать пост по его тональности относительно торговли акциями.\n",
    "Верни ТОЛЬКО ОДНО ЧИСЛО: 1 (покупка/бычий), 0 (нейтральный), -1 (продажа/медвежий)\n",
    "\n",
    "Вот примеры:\n",
    "\n",
    "Пост: \"Отличный отчет! Ракета готова к взлету, закупаюсь на всю котлету #AAPL\"\n",
    "Ответ: 1\n",
    "\n",
    "Пост: \"Фиксанул прибыль по $GAZP. Рынок выглядит перегретым, возможна коррекция.\"\n",
    "Ответ: -1\n",
    "\n",
    "Пост: \"Сегодня ВТБ опубликует финансовые результаты за квартал. Интересно посмотреть.\"\n",
    "Ответ: 0\n",
    "\n",
    "Пост: \"Что думаете про $SBER? Вроде и дивы хорошие, но геополитика давит...\"\n",
    "Ответ: 0\n",
    "\n",
    "Пост: \"Зашортил сбер перед отчетом\"\n",
    "Ответ: -1\n",
    "\n",
    "Пост: \"пора докупать сбербанк пока дешевый\"\n",
    "Ответ: 1\n",
    "\n",
    "Пост: \"какие прогнозы по втб?\"\n",
    "Ответ: 0\n",
    "\n",
    "Теперь твоя задача: проанализируй следующий пост и верни ТОЛЬКО число.\n",
    "\"\"\"\n",
    "\n",
    "# query = \"беру сбер в шорт\"\n",
    "\n",
    "# # --- Подготовка ввода для модели Qwen ---\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": system_prompt},\n",
    "#     {\"role\": \"user\", \"content\": query}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:29:24.509224Z",
     "iopub.status.busy": "2025-05-02T18:29:24.508899Z",
     "iopub.status.idle": "2025-05-02T18:29:24.514643Z",
     "shell.execute_reply": "2025-05-02T18:29:24.513947Z",
     "shell.execute_reply.started": "2025-05-02T18:29:24.509200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Ты - ИИ для анализа финансового сентимента постов.\n",
    "Твоя задача - классифицировать пост по его тональности относительно торговли акциями.\n",
    "\n",
    "Категории и правила:\n",
    "*   **1 (Покупка/Бычий):** Пост явно выражает намерение купить, решение о покупке, удержание лонга с ожиданием роста, или описывает сильные позитивные факторы, прямо указывающие на вероятный рост цены акции. Ключевые слова/идеи: \"купил\", \"докупаю\", \"лонг\", \"ракета\", \"рост\", \"пробой вверх\", \"отчет супер\", \"пора брать\", \"держать дальше\", \"потенциал есть\".\n",
    "*   **-1 (Продажа/Медвежий):** Пост явно выражает намерение продать, решение о продаже, открытие/удержание шорта с ожиданием падения, или описывает сильные негативные факторы, прямо указывающие на вероятное падение цены акции. Ключевые слова/идеи: \"продал\", \"шорт\", \"сливаю\", \"падение\", \"дно не найдено\", \"отчет плохой\", \"пора выходить\", \"фиксация убытка\", \"коррекция\".\n",
    "*   **0 (Нейтральный):** Пост НЕ содержит явного торгового сигнала на покупку или продажу. Сюда относятся:\n",
    "    *   Вопросы о цене или прогнозах (\"что думаете?\", \"куда пойдет?\").\n",
    "    *   Констатация фактов или новостей без явной оценки влияния на цену (\"вышел отчет\", \"сегодня дивгэп\").\n",
    "    *   Смешанные сигналы или сомнения (\"вроде растет, но страшно\", \"с одной стороны..., с другой...\").\n",
    "    *   Общие рыночные рассуждения без привязки к конкретному действию.\n",
    "    *   Фиксация прибыли или убытка *без явного прогноза* дальнейшего движения (\"закрыл позицию\", \"вышел в ноль\").\n",
    "    *   Неясные или неинформативные сообщения.\n",
    "\n",
    "Примеры:\n",
    "Пост: \"Отличный отчет! Ракета готова к взлету, закупаюсь на всю котлету #AAPL\"\n",
    "Ответ: 1\n",
    "Пост: \"Фиксанул прибыль по $GAZP. Рынок выглядит перегретым, возможна коррекция.\"\n",
    "Ответ: -1\n",
    "Пост: \"Сегодня ВТБ опубликует финансовые результаты за квартал. Интересно посмотреть.\"\n",
    "Ответ: 0\n",
    "Пост: \"Что думаете про $SBER? Вроде и дивы хорошие, но геополитика давит...\"\n",
    "Ответ: 0\n",
    "Пост: \"Зашортил сбер перед отчетом\"\n",
    "Ответ: -1\n",
    "Пост: \"пора докупать сбербанк пока дешевый\"\n",
    "Ответ: 1\n",
    "Пост: \"какие прогнозы по втб?\"\n",
    "Ответ: 0\n",
    "Пост: \"Закрыл лонг по Лукойлу в плюс, пока понаблюдаю со стороны\"\n",
    "Ответ: 0\n",
    "\n",
    "Верни ТОЛЬКО ОДНО число: 1, 0 или -1.\n",
    "\n",
    "Проанализируй следующий пост пользователя и предоставь числовой ответ:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:31:01.435235Z",
     "iopub.status.busy": "2025-05-02T18:31:01.434547Z",
     "iopub.status.idle": "2025-05-02T18:31:01.438367Z",
     "shell.execute_reply": "2025-05-02T18:31:01.437832Z",
     "shell.execute_reply.started": "2025-05-02T18:31:01.435208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Ты - ИИ для анализа финансового сентимента постов.\n",
    "Твоя задача - классифицировать пост по его тональности относительно торговли акциями.\n",
    "Верни ТОЛЬКО ОДНО ЧИСЛО: 1 (покупаем актив/бычий), 0 (нейтральный), -1 (продаем актив /медвежий)\n",
    "\n",
    "Проанализируй следующий пост и верни ТОЛЬКО число.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Применяем шаблон чата Qwen, отключаем \"thinking\"\n",
    "# tokenize=True вернет input_ids и attention_mask сразу\n",
    "model_inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False, # Отключаем режим размышления для простой задачи\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "print(f\"\\nЗапрос к модели:\\nSystem: {system_prompt}\\nUser: {query}\")\n",
    "print(\"\\nГенерация ответа...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- Генерация ответа ---\n",
    "# Нет необходимости явно указывать eos_token_id при enable_thinking=False и do_sample=False, \n",
    "# модель должна остановиться сама или на max_new_tokens\n",
    "outputs = model.generate(\n",
    "    model_inputs, # Передаем input_ids и attention_mask (если есть)\n",
    "    max_new_tokens=10, # Мало токенов для простого ответа\n",
    "    do_sample=False,   # Детерминированный вывод\n",
    "    pad_token_id=tokenizer.eos_token_id \n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Время генерации: {end_time - start_time:.2f} сек\")\n",
    "\n",
    "# --- Декодирование и вывод ---\n",
    "# Декодируем только сгенерированную часть\n",
    "# model_inputs может быть словарем, используем input_ids\n",
    "input_ids_len = model_inputs['input_ids'].shape[1] if isinstance(model_inputs, dict) else model_inputs.shape[1]\n",
    "response_ids = outputs[0][input_ids_len:] \n",
    "response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "print(f\"\\nСгенерированный ответ модели (сырой):\")\n",
    "print(response_text)\n",
    "\n",
    "# Попытка извлечь число\n",
    "try:\n",
    "    sentiment_score = int(response_text)\n",
    "    if sentiment_score not in [-1, 0, 1]:\n",
    "        print(f\"\\nПредупреждение: Модель вернула некорректное число {sentiment_score}. Используется 0.\")\n",
    "        sentiment_score = 0\n",
    "    print(f\"\\nИзвлеченное значение сентимента: {sentiment_score}\")\n",
    "except ValueError:\n",
    "    print(f\"\\nНе удалось извлечь число из ответа: '{response_text}'. Используется 0.\")\n",
    "    sentiment_score = 0 # Значение по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:21:31.572162Z",
     "iopub.status.busy": "2025-05-02T18:21:31.571606Z",
     "iopub.status.idle": "2025-05-02T18:21:31.715171Z",
     "shell.execute_reply": "2025-05-02T18:21:31.714581Z",
     "shell.execute_reply.started": "2025-05-02T18:21:31.572139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>processed_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78592a62-93f9-4940-b914-a6cb8baafaff</td>\n",
       "      <td>🪓 {$SGZH} — полностью исключают из основного и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47ed3f81-fead-4d6e-9186-d2b21de56e4c</td>\n",
       "      <td>На этот раз таких активов оказалось неожиданно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01d56071-766d-40a1-801c-4572e703fdc6</td>\n",
       "      <td>Market Power 🗣 про {$SBER}:\\n\\n\"Сбер превосход...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761e88a9-0b4e-4a46-b569-ca92762b78b4</td>\n",
       "      <td>•29.08.2023 {$SGZH} \\nСегежа Групп опубликует ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66369560-83a0-4456-80de-2ba0239b4e1f</td>\n",
       "      <td>{$SBER}\\nЦБ готов идти на более жесткие меры, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>c91e9965-9574-463d-86f2-70d472d4f3a9</td>\n",
       "      <td>{$LKOH} \\n‼️Давайте сравним акции номер один 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5</td>\n",
       "      <td>{$SBER} )))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>faf7264b-67fe-4d5d-998c-9e2c026f3b76</td>\n",
       "      <td>{$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>16c1315f-d62e-4412-8faa-48542fe4b437</td>\n",
       "      <td>{$SGZH} \\n﻿Сдувается мыльный пузырь, что и тре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>b4892d9b-3290-4b62-b494-293487fb3f2d</td>\n",
       "      <td>Интересно, что наш рынок давно уже привык к са...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   post_id  \\\n",
       "0     78592a62-93f9-4940-b914-a6cb8baafaff   \n",
       "1     47ed3f81-fead-4d6e-9186-d2b21de56e4c   \n",
       "2     01d56071-766d-40a1-801c-4572e703fdc6   \n",
       "3     761e88a9-0b4e-4a46-b569-ca92762b78b4   \n",
       "4     66369560-83a0-4456-80de-2ba0239b4e1f   \n",
       "...                                    ...   \n",
       "2995  c91e9965-9574-463d-86f2-70d472d4f3a9   \n",
       "2996  e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5   \n",
       "2997  faf7264b-67fe-4d5d-998c-9e2c026f3b76   \n",
       "2998  16c1315f-d62e-4412-8faa-48542fe4b437   \n",
       "2999  b4892d9b-3290-4b62-b494-293487fb3f2d   \n",
       "\n",
       "                                        processed_posts  \n",
       "0     🪓 {$SGZH} — полностью исключают из основного и...  \n",
       "1     На этот раз таких активов оказалось неожиданно...  \n",
       "2     Market Power 🗣 про {$SBER}:\\n\\n\"Сбер превосход...  \n",
       "3     •29.08.2023 {$SGZH} \\nСегежа Групп опубликует ...  \n",
       "4     {$SBER}\\nЦБ готов идти на более жесткие меры, ...  \n",
       "...                                                 ...  \n",
       "2995  {$LKOH} \\n‼️Давайте сравним акции номер один 1...  \n",
       "2996                                        {$SBER} )))  \n",
       "2997  {$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...  \n",
       "2998  {$SGZH} \\n﻿Сдувается мыльный пузырь, что и тре...  \n",
       "2999  Интересно, что наш рынок давно уже привык к са...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_qwen_2000 = pd.read_csv(\"/kaggle/input/qwen-dataset/data_qwen_raw.csv\")\n",
    "posts_qwen_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:31:38.910491Z",
     "iopub.status.busy": "2025-05-02T18:31:38.909835Z",
     "iopub.status.idle": "2025-05-02T19:10:32.341857Z",
     "shell.execute_reply": "2025-05-02T19:10:32.340995Z",
     "shell.execute_reply.started": "2025-05-02T18:31:38.910458Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обработку 3000 постов с моделью Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Классификация Qwen:   0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Классификация Qwen: 100%|██████████| 3000/3000 [38:53<00:00,  1.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка завершена за 2333.41 сек (0.778 сек/пост).\n",
      "\n",
      "Пример результатов Qwen:\n",
      "                                post_id  \\\n",
      "0  78592a62-93f9-4940-b914-a6cb8baafaff   \n",
      "1  47ed3f81-fead-4d6e-9186-d2b21de56e4c   \n",
      "2  01d56071-766d-40a1-801c-4572e703fdc6   \n",
      "3  761e88a9-0b4e-4a46-b569-ca92762b78b4   \n",
      "4  66369560-83a0-4456-80de-2ba0239b4e1f   \n",
      "\n",
      "                                     processed_posts  \\\n",
      "0  🪓 {$SGZH} — полностью исключают из основного и...   \n",
      "1  На этот раз таких активов оказалось неожиданно...   \n",
      "2  Market Power 🗣 про {$SBER}:\\n\\n\"Сбер превосход...   \n",
      "3  •29.08.2023 {$SGZH} \\nСегежа Групп опубликует ...   \n",
      "4  {$SBER}\\nЦБ готов идти на более жесткие меры, ...   \n",
      "\n",
      "   qwen_14b_instruct_sentiment  \n",
      "0                           -1  \n",
      "1                            0  \n",
      "2                            1  \n",
      "3                            0  \n",
      "4                           -1  \n",
      "\n",
      "Распределение полученных классов Qwen:\n",
      "qwen_14b_instruct_sentiment\n",
      " 0    1050\n",
      "-1    1024\n",
      " 1     926\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def classify_sentiment_qwen_batch( # Немного изменил имя для ясности\n",
    "    df: pd.DataFrame,\n",
    "    model, \n",
    "    tokenizer, \n",
    "    system_prompt: str,\n",
    "    text_column: str = \"processed_posts\",\n",
    "    output_column: str = \"qwen_sentiment\", # Имя колонки по умолчанию\n",
    "    max_new_tokens: int = 10,\n",
    "    default_sentiment: int = 0, \n",
    "    batch_size: int = 1 # Оставляем 1 для простоты, т.к. батчинг требует паддинга\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Классифицирует сентимент постов в DataFrame с помощью модели Qwen.\n",
    "    Использует метод передачи результата apply_chat_template напрямую в generate.\n",
    "\n",
    "    Args:\n",
    "        df: Входной DataFrame.\n",
    "        model: Загруженная модель Qwen.\n",
    "        tokenizer: Загруженный токенизатор Qwen.\n",
    "        system_prompt: Системный промпт для модели.\n",
    "        text_column: Имя колонки с текстом постов.\n",
    "        output_column: Имя новой колонки для сохранения результата.\n",
    "        max_new_tokens: Максимальное количество генерируемых токенов.\n",
    "        default_sentiment: Значение, присваиваемое в случае ошибки парсинга ответа.\n",
    "        batch_size: Размер батча (пока поддерживается только 1).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame с добавленной колонкой output_column.\n",
    "    \"\"\"\n",
    "    if batch_size != 1:\n",
    "        raise NotImplementedError(\"Batch size > 1 requires padding and attention mask handling, currently not implemented here.\")\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Начинаем обработку {len(df)} постов с моделью Qwen...\")\n",
    "    start_total_time = time.time()\n",
    "    \n",
    "    # Итерация по постам с использованием tqdm для прогресс-бара\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Классификация Qwen\"):\n",
    "        post_text = row[text_column]\n",
    "        \n",
    "        # Проверка на пустой или некорректный текст\n",
    "        if not isinstance(post_text, str) or not post_text.strip():\n",
    "            results.append(default_sentiment)\n",
    "            continue\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": post_text}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # 1. Токенизация (сразу на GPU)\n",
    "            #    Эта часть теперь основана на вашем рабочем варианте\n",
    "            torch.cuda.empty_cache() \n",
    "            model_inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                enable_thinking=False, \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "            \n",
    "            # Определяем длину входных данных ДО генерации\n",
    "            # Эта логика для определения input_ids_len теперь здесь\n",
    "            if isinstance(model_inputs, dict):\n",
    "                input_ids_len = model_inputs['input_ids'].shape[1]\n",
    "            elif hasattr(model_inputs, 'shape'): # Проверка на тензор или подобный объект\n",
    "                 input_ids_len = model_inputs.shape[1]\n",
    "            else:\n",
    "                # Неожиданный тип, пытаемся угадать или пропускаем\n",
    "                print(f\"Предупреждение: Не удалось определить input_ids_len для поста {index}. Тип: {type(model_inputs)}. Пропуск.\")\n",
    "                results.append(default_sentiment)\n",
    "                continue\n",
    "\n",
    "            # 2. Генерация (передаем model_inputs напрямую)\n",
    "            outputs = model.generate(\n",
    "                model_inputs, # Передаем результат токенизации напрямую\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.eos_token_id \n",
    "            )\n",
    "            # 3. Декодирование\n",
    "            response_ids = outputs[0][input_ids_len:] # Используем ранее вычисленную длину\n",
    "            response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "            # 4. Парсинг ответа\n",
    "            try:\n",
    "                sentiment_score = int(response_text)\n",
    "                if sentiment_score not in [-1, 0, 1]:\n",
    "                     # print(f\"Предупр: Некорр. число {sentiment_score} для поста {index}. Ответ: '{response_text}'.\") # Отладка\n",
    "                     results.append(default_sentiment)\n",
    "                else:\n",
    "                    results.append(sentiment_score)\n",
    "            except ValueError:\n",
    "                # print(f\"Предупр: Не число для поста {index}. Ответ: '{response_text}'.\") # Отладка\n",
    "                results.append(default_sentiment)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Обработка других ошибок (например, OOM при генерации)\n",
    "            print(f\"Критическая ошибка при обработке поста {index}: {e}\")\n",
    "            print(f\"Текст поста: {post_text[:100]}...\") \n",
    "            results.append(default_sentiment) # Добавляем значение по умолчанию\n",
    "            # time.sleep(1) # Можно добавить паузу при частых ошибках\n",
    "\n",
    "    # Добавляем результаты как новую колонку\n",
    "    df[output_column] = results\n",
    "    \n",
    "    end_total_time = time.time()\n",
    "    total_time = end_total_time - start_total_time\n",
    "    avg_time = total_time / len(df) if len(df) > 0 else 0\n",
    "    print(f\"Обработка завершена за {total_time:.2f} сек ({avg_time:.3f} сек/пост).\")\n",
    "    return df\n",
    "\n",
    "# --- Пример вызова функции ---\n",
    "# Убедитесь, что model (например, Qwen/Qwen3-14B-Instruct) и tokenizer загружены\n",
    "# и DataFrame posts_llama_2000 существует\n",
    "\n",
    "df_for_qwen_processing = posts_qwen_2000.copy() \n",
    "\n",
    "df_classified_qwen = classify_sentiment_qwen_batch(\n",
    "    df=df_for_qwen_processing,\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    system_prompt=system_prompt,\n",
    "    text_column=\"processed_posts\", \n",
    "    output_column=\"qwen_14b_instruct_sentiment\" # Укажите желаемое имя колонки\n",
    ")\n",
    "\n",
    "# --- Проверка результатов ---\n",
    "print(\"\\nПример результатов Qwen:\")\n",
    "print(df_classified_qwen.head())\n",
    "\n",
    "print(\"\\nРаспределение полученных классов Qwen:\")\n",
    "print(df_classified_qwen['qwen_14b_instruct_sentiment'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:18:32.729080Z",
     "iopub.status.busy": "2025-05-02T19:18:32.728770Z",
     "iopub.status.idle": "2025-05-02T19:18:32.746062Z",
     "shell.execute_reply": "2025-05-02T19:18:32.745469Z",
     "shell.execute_reply.started": "2025-05-02T19:18:32.729054Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>processed_posts</th>\n",
       "      <th>qwen_14b_instruct_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78592a62-93f9-4940-b914-a6cb8baafaff</td>\n",
       "      <td>🪓 {$SGZH} — полностью исключают из основного и...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47ed3f81-fead-4d6e-9186-d2b21de56e4c</td>\n",
       "      <td>На этот раз таких активов оказалось неожиданно...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01d56071-766d-40a1-801c-4572e703fdc6</td>\n",
       "      <td>Market Power 🗣 про {$SBER}:\\n\\n\"Сбер превосход...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761e88a9-0b4e-4a46-b569-ca92762b78b4</td>\n",
       "      <td>•29.08.2023 {$SGZH} \\nСегежа Групп опубликует ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66369560-83a0-4456-80de-2ba0239b4e1f</td>\n",
       "      <td>{$SBER}\\nЦБ готов идти на более жесткие меры, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>c91e9965-9574-463d-86f2-70d472d4f3a9</td>\n",
       "      <td>{$LKOH} \\n‼️Давайте сравним акции номер один 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5</td>\n",
       "      <td>{$SBER} )))</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>faf7264b-67fe-4d5d-998c-9e2c026f3b76</td>\n",
       "      <td>{$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>16c1315f-d62e-4412-8faa-48542fe4b437</td>\n",
       "      <td>{$SGZH} \\n﻿Сдувается мыльный пузырь, что и тре...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>b4892d9b-3290-4b62-b494-293487fb3f2d</td>\n",
       "      <td>Интересно, что наш рынок давно уже привык к са...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   post_id  \\\n",
       "0     78592a62-93f9-4940-b914-a6cb8baafaff   \n",
       "1     47ed3f81-fead-4d6e-9186-d2b21de56e4c   \n",
       "2     01d56071-766d-40a1-801c-4572e703fdc6   \n",
       "3     761e88a9-0b4e-4a46-b569-ca92762b78b4   \n",
       "4     66369560-83a0-4456-80de-2ba0239b4e1f   \n",
       "...                                    ...   \n",
       "2995  c91e9965-9574-463d-86f2-70d472d4f3a9   \n",
       "2996  e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5   \n",
       "2997  faf7264b-67fe-4d5d-998c-9e2c026f3b76   \n",
       "2998  16c1315f-d62e-4412-8faa-48542fe4b437   \n",
       "2999  b4892d9b-3290-4b62-b494-293487fb3f2d   \n",
       "\n",
       "                                        processed_posts  \\\n",
       "0     🪓 {$SGZH} — полностью исключают из основного и...   \n",
       "1     На этот раз таких активов оказалось неожиданно...   \n",
       "2     Market Power 🗣 про {$SBER}:\\n\\n\"Сбер превосход...   \n",
       "3     •29.08.2023 {$SGZH} \\nСегежа Групп опубликует ...   \n",
       "4     {$SBER}\\nЦБ готов идти на более жесткие меры, ...   \n",
       "...                                                 ...   \n",
       "2995  {$LKOH} \\n‼️Давайте сравним акции номер один 1...   \n",
       "2996                                        {$SBER} )))   \n",
       "2997  {$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...   \n",
       "2998  {$SGZH} \\n﻿Сдувается мыльный пузырь, что и тре...   \n",
       "2999  Интересно, что наш рынок давно уже привык к са...   \n",
       "\n",
       "      qwen_14b_instruct_sentiment  \n",
       "0                              -1  \n",
       "1                               0  \n",
       "2                               1  \n",
       "3                               0  \n",
       "4                              -1  \n",
       "...                           ...  \n",
       "2995                            1  \n",
       "2996                            0  \n",
       "2997                            0  \n",
       "2998                           -1  \n",
       "2999                           -1  \n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:24:51.481898Z",
     "iopub.status.busy": "2025-05-02T18:24:51.481585Z",
     "iopub.status.idle": "2025-05-02T18:24:51.488260Z",
     "shell.execute_reply": "2025-05-02T18:24:51.487431Z",
     "shell.execute_reply.started": "2025-05-02T18:24:51.481872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['🪓 {$SGZH} — полностью исключают из основного индекса Мосбиржи. Ее место займет 📱 $YDEX.',\n",
       "       'На этот раз таких активов оказалось неожиданно много, ведь осень обычно не является заметным дивидендным сезоном. До конца года около 20 эмитентов, в том числе {$LKOH} ЛУКОЙЛ, {$RTKM} Ростелеком, {$GMKN} Норникель и {$PHOR} Фосагро, планируют выплатить дивиденд.',\n",
       "       'Market Power 🗣 про {$SBER}:\\n\\n\"Сбер превосходит себя\\nБольшой зеленый банк опубликовал отчет за 2 квартал и 1 полугодие\\n\\nСбер\\nМСар = ₽6 трлн\\n\\n📊Итоги 2 квартала\\n- процентные доходы: ₽598 млрд;\\n- комиссионные доходы: ₽187 млрд;\\n- чистая прибыль: ₽380 млрд;\\n- рентабельность капитала: 26%;\\n- активные физлица: 107 млн (+1% с начала года);\\n- ежемесячные пользователи СберОнлайн: 80 млн (+1,5% с начала года);\\n- розничный кредитный портфель: ₽14 трлн (+12% с начала года);\\n- ипотечный портфель: ₽8,5 трлн (+12% с начала года).\\n\\n ❗️Стоит отметить, что прибыль за 2 квартал оказалась даже выше консенсус-прогнозов рынка. Чистая прибыль за полгода составила ₽738 млрд. \\n\\n🥸Рост процентных доходов банк объясняет увеличением объема работающих активов и восстановления маржинальности бизнеса. Комиссионные же выросли на фоне роста доходов от операций с банковскими картами и расчетно-кассового обслуживания.\"',\n",
       "       '•29.08.2023 {$SGZH} \\nСегежа Групп опубликует финансовые результаты по МСФО за I полугодие 2023 г.',\n",
       "       '{$SBER}\\nЦБ готов идти на более жесткие меры, чтобы вернуть инфляцию на уровень 4% в 2025 году, — глава ЦБ Эльвира Набиуллина. В том числе, не исключается дальнейшее повышение ключевой ставки.',\n",
       "       '{$SBER} дивиденды)',\n",
       "       'ЛУКОЙЛ. Перекупленность нарастает\\n\\nВ предыдущий торговый день акции компании ЛУКОЙЛ выросли на 0,51%, закрытие прошло на отметке 4342 руб. Бумага выглядела на уровне рынка, прибавившего 0,74%. Объем торгов акцией на основном рынке составил 1,8 млрд руб. при среднем за месяц 1,8 млрд руб.\\n\\nКраткосрочная картина:\\n•Бумаги ЛУКОЙЛа продолжают расти, накапливая перекупленность. По осциллятору RSI на таймфрейме D1 она фиксируется уже третий день подряд. Чем ближе выходные, тем выше шансы, что такая техническая картина приведет к усилению распродаж и переходу к коррекции. Ее потенциал может быть в районе 4210-4240 руб.\\n\\n•При этом восходящий тренд, целью которого может быть уровень 4520 руб., остается актуален. Если экстраполировать темпы роста предыдущих дней вперед, инструмент может войти в зону 4430–4520 руб. уже на следующей неделе.\\n\\n•Отчеты отдельных нефтяных компаний позволяют предположить, что II полугодие для ЛУКОЙЛа было достаточно сильным. Это значит, что есть надежда на хорошие финальные дивиденды за 2022 г. Этот фактор может поддерживать интерес к акциям компании.\\n\\n•Однако покупки сдерживаются повышенным уровнем неопределенности в секторе. Кроме того, компания могла сильнее других пострадать из-за внешних ограничений, что может негативно сказаться на будущих дивидендных выплатах.\\n\\nВнешний фон:\\nВнешний фон с утра складывается смешанный. Азиатские индексы торгуются разнонаправленно. Фьючерс на S&P 500 падает на 0,04%. Нефть Brent сегодня в минусе на 0,4%.\\n\\nДолгосрочная картина\\n\\n•Долгосрочный взгляд на акции умеренно позитивный. Фундаментальные факторы формируют достаточно противоречивую картину. Эмбарго на нефть и нефтепродукты в ЕС несет ощутимые риски для компании, но перенаправление поставок может позволить сохранить достойные прибыли на фоне высоких мировых цен на нефть.\\n\\n•Снизу значимой зоной поддержки выступает коридор 3600–3700 руб. Целью восстановления при благоприятной конъюнктуре может быть круглая отметка 5000 руб.\\n📍Источник: БКС {$LKOH} \\n\\n👉В рамках стратегии [&Абсолютная величина](    акции подбираются на основе концепции диверсификации, где мы удерживаем позиции от недели до месяца, в редких случаях и более. \\n\\n👉В рамках стратегии [&Грош цена. На пенсию внукам](  мы удерживаем позиции более длительный период времени. Подходит для консервативных инвесторов. \\n\\n👉 [&Национальное достояние](   Моя новая, заключительная стратегия, базированная на сырьевой добыче. \\nРоссия занимает ведущее место в мире по запасам нефти, газа, угля. На этом мы и будем зарабатывать.\\n\\n✅👉Полный перечень подарков, придётся по вкусу каждому. Выбирай сам)',\n",
       "       '{$MMU3} {$SBER} у кого еще висят утренние заявки? и по какой цене они исполнят интересно',\n",
       "       'Самое негативное что могло быть – санкции на НКЦ, которых мы не увидели. Все эти компании не окажут существенное влияние на индекс IMOEX. На ожиданиях мы падали, так что я предположу следующее: худшего сценария мы не увидели, люди в любом случае начнут откупать свои шорты, а кто-то снова набирать позиции в акциях, которые не попали под санкции (многое дают по хорошим ценам). Лично я ставлю на рост в ближайшее время (вероятность роста выше падения). {$SBER} у меня фаворит в данном случае.',\n",
       "       '{$MTLR} валите ее до 305, там закупимся'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified_qwen.processed_posts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:16:57.044691Z",
     "iopub.status.busy": "2025-05-02T18:16:57.044218Z",
     "iopub.status.idle": "2025-05-02T18:20:49.066338Z",
     "shell.execute_reply": "2025-05-02T18:20:49.065222Z",
     "shell.execute_reply.started": "2025-05-02T18:16:57.044667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig # Импортируем конфиг\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-14B\" \n",
    "\n",
    "# Конфигурация для 4-битной квантизации (NF4)\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16, # Тип для вычислений (рекомендуется bfloat16)\n",
    "#     bnb_4bit_quant_type=\"nf4\",           # Тип квантизации\n",
    "#     bnb_4bit_use_double_quant=True,     # Использовать двойную квантизацию для экономии\n",
    "# )\n",
    "\n",
    "# Или конфигурация для 8-битной квантизации (если 4-битная дает плохое качество)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_8bit=True,\n",
    ")\n",
    "\n",
    "print(f\"Загрузка токенизатора: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "print(\"Загрузка квантизированной модели...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\", # device_map=\"auto\" хорошо работает с bitsandbytes\n",
    "    quantization_config=quantization_config, # Применяем конфиг квантизации\n",
    "    trust_remote_code=True \n",
    "    # max_memory можно убрать или оставить, но теперь модель должна легко помещаться\n",
    ")\n",
    "print(\"Квантизированная модель загружена.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7310590,
     "sourceId": 11649552,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7312603,
     "sourceId": 11652388,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
