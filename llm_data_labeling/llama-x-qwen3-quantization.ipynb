{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import accelerate\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"your token\"\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# posts_llama_2000 = pd.read_csv(\"/kaggle/input/data-for-llama-labeling/data_llama_raw.csv\")\n",
    "posts_llama_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "max_memory_map = {\n",
    "    0: \"14GiB\", \n",
    "    1: \"14GiB\"\n",
    "}\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, legacy=False)\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å device_map='auto' –∏ max_memory...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    max_memory=max_memory_map,\n",
    ")\n",
    "clear_output()\n",
    "print(\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"–¢—ã - –ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ –ø–æ—Å—Ç–æ–≤.\n",
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç –ø–æ –µ–≥–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–æ—Ä–≥–æ–≤–ª–∏ –∞–∫—Ü–∏—è–º–∏.\n",
    "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –û–î–ù–û –ß–ò–°–õ–û: 1 (–ø–æ–∫—É–ø–∫–∞/–±—ã—á–∏–π), 0 (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π), -1 (–ø—Ä–æ–¥–∞–∂–∞/–º–µ–¥–≤–µ–∂–∏–π). –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.\n",
    "\n",
    "–í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã:\n",
    "\n",
    "–ü–æ—Å—Ç: \"–û—Ç–ª–∏—á–Ω—ã–π –æ—Ç—á–µ—Ç! –†–∞–∫–µ—Ç–∞ –≥–æ—Ç–æ–≤–∞ –∫ –≤–∑–ª–µ—Ç—É, –∑–∞–∫—É–ø–∞—é—Å—å –Ω–∞ –≤—Å—é –∫–æ—Ç–ª–µ—Ç—É #SBER\"\n",
    "–û—Ç–≤–µ—Ç: 1\n",
    "–ü–æ—Å—Ç: \"–§–∏–∫—Å–∞–Ω—É–ª –ø—Ä–∏–±—ã–ª—å –ø–æ $GAZP. –†—ã–Ω–æ–∫ –≤—ã–≥–ª—è–¥–∏—Ç –ø–µ—Ä–µ–≥—Ä–µ—Ç—ã–º, –≤–æ–∑–º–æ–∂–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è.\"\n",
    "–û—Ç–≤–µ—Ç: -1\n",
    "–ü–æ—Å—Ç: \"–°–µ–≥–æ–¥–Ω—è –í–¢–ë –æ–ø—É–±–ª–∏–∫—É–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ –∫–≤–∞—Ä—Ç–∞–ª. –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å.\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "–ü–æ—Å—Ç: \"–ß—Ç–æ –¥—É–º–∞–µ—Ç–µ –ø—Ä–æ $SBER? –í—Ä–æ–¥–µ –∏ –¥–∏–≤—ã —Ö–æ—Ä–æ—à–∏–µ, –Ω–æ –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞ –¥–∞–≤–∏—Ç...\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "–ü–æ—Å—Ç: \"–ó–∞—à–æ—Ä—Ç–∏–ª —Å–±–µ—Ä –ø–µ—Ä–µ–¥ –æ—Ç—á–µ—Ç–æ–º\"\n",
    "–û—Ç–≤–µ—Ç: -1\n",
    "–ü–æ—Å—Ç: \"–ø–æ—Ä–∞ –¥–æ–∫—É–ø–∞—Ç—å —Å–±–µ—Ä–±–∞–Ω–∫ –ø–æ–∫–∞ –¥–µ—à–µ–≤—ã–π\"\n",
    "–û—Ç–≤–µ—Ç: 1\n",
    "–ü–æ—Å—Ç: \"–∫–∞–∫–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –ø–æ –≤—Ç–±?\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å —Ç–≤–æ—è –∑–∞–¥–∞—á–∞: –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ.\n",
    "\"\"\"\n",
    "\n",
    "# query = \"–ø–æ—Ä–∞ —Å–ª–∏–≤–∞—Ç—å —ç—Ç–æ –¥–µ—Ä—å–º–æ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "]\n",
    "\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\" # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã PyTorch\n",
    ")\n",
    "\n",
    "input_ids = input_ids.to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "print(f\"\\n–ó–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏:\\nSystem: {system_prompt}\\nUser: {query}\")\n",
    "print(\"\\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...\")\n",
    "\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=20,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=False, \n",
    "    pad_token_id=tokenizer.eos_token_id \n",
    ")\n",
    "\n",
    "response_ids = outputs[0][input_ids.shape[1]:]\n",
    "response_text = tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "\n",
    "print(f\"\\n–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (—Å—ã—Ä–æ–π):\")\n",
    "print(response_text)\n",
    "\n",
    "try:\n",
    "    sentiment_score = int(response_text.strip())\n",
    "    print(f\"\\n–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞: {sentiment_score}\")\n",
    "except ValueError:\n",
    "    print(f\"\\n–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ –æ—Ç–≤–µ—Ç–∞: '{response_text.strip()}'\")\n",
    "    print(\"–í–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, query):\n",
    "    # Format input with system prompt and user query\n",
    "    prompt = f\"<|system|>\\n{system_prompt}\\n<|user|>\\n{query}\\n<|assistant|>\"\n",
    "    \n",
    "    # Generate response\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=10,  # Small value since we only need a single number\n",
    "        # temperature=0.1,    # Low temperature for consistent results\n",
    "        do_sample=False     # Deterministic generation\n",
    "    )\n",
    "    \n",
    "    # Decode the response, removing the input prompt\n",
    "    response = tokenizer.decode(output[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "    return response\n",
    "\n",
    "# Generate sentiment analysis result\n",
    "sentiment_result = generate_response(system_prompt, query)\n",
    "print(f\"–°–µ–Ω—Ç–∏–º–µ–Ω—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {sentiment_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{query}\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...\")\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=10,  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–∞–ª–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞\n",
    "    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)\n",
    "    # temperature=0.1,\n",
    "    # top_k=50,\n",
    "    # top_p=0.95,\n",
    "    # do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º pad_token_id, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\n",
    ")\n",
    "\n",
    "# 5. –î–µ–∫–æ–¥–∏—Ä—É–π—Ç–µ —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —á–∞—Å—Ç—å –æ—Ç–≤–µ—Ç–∞\n",
    "generated_token_ids = outputs[0][input_ids.shape[-1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.auto import tqdm \n",
    "import time # –î–ª—è –Ω–µ–±–æ–ª—å—à–æ–π –ø–∞—É–∑—ã –∏ –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ–≥—Ä–µ–≤–∞/–æ—à–∏–±–æ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify_sentiment_llama(\n",
    "    df: pd.DataFrame,\n",
    "    model, # –¢–∏–ø: AutoModelForCausalLM\n",
    "    tokenizer, # –¢–∏–ø: AutoTokenizer\n",
    "    system_prompt: str,\n",
    "    text_column: str = \"processed_posts\",\n",
    "    output_column: str = \"llama_sentiment\",\n",
    "    max_new_tokens: int = 10,\n",
    "    default_sentiment: int = 0, # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ\n",
    "    batch_size: int = 1 # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –æ–¥–Ω–æ–º—É –ø–æ—Å—Ç—É (–ø—Ä–æ—â–µ –¥–ª—è –Ω–∞—á–∞–ª–∞)\n",
    "                       # –ë–∞—Ç—á–∏–Ω–≥ > 1 —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–π –ª–æ–≥–∏–∫–∏ –ø–∞–¥–¥–∏–Ω–≥–∞\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç –ø–æ—Å—Ç–æ–≤ –≤ DataFrame —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ Llama.\n",
    "\n",
    "    Args:\n",
    "        df: –í—Ö–æ–¥–Ω–æ–π DataFrame.\n",
    "        model: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Llama (AutoModelForCausalLM).\n",
    "        tokenizer: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä Llama (AutoTokenizer).\n",
    "        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏.\n",
    "        text_column: –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º –ø–æ—Å—Ç–æ–≤.\n",
    "        output_column: –ò–º—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.\n",
    "        max_new_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "        default_sentiment: –ó–Ω–∞—á–µ–Ω–∏–µ, –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º–æ–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞.\n",
    "        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–æ–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 1).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–æ–π output_column.\n",
    "    \"\"\"\n",
    "    if batch_size != 1:\n",
    "        raise NotImplementedError(\"Batch size > 1 is not yet implemented in this function.\")\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–∫–µ–Ω—ã –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–¥–∏–Ω —Ä–∞–∑\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –ø–æ—Å—Ç–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞\n",
    "    print(f\"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(df)} –ø–æ—Å—Ç–æ–≤...\")\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤\"):\n",
    "        post_text = row[text_column]\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "        if not isinstance(post_text, str) or not post_text.strip():\n",
    "            print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü—Ä–æ–ø—É—â–µ–Ω –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–æ—Å—Ç —Å –∏–Ω–¥–µ–∫—Å–æ–º {index}\")\n",
    "            results.append(default_sentiment)\n",
    "            continue\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": post_text}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # 1. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "            input_ids = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device) # –°—Ä–∞–∑—É –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "            # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è\n",
    "            outputs = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                eos_token_id=terminators,\n",
    "                do_sample=False, # –í–∞–∂–Ω–æ –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "                pad_token_id=tokenizer.eos_token_id \n",
    "            )\n",
    "            \n",
    "            # 3. –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —á–∞—Å—Ç–∏\n",
    "            response_ids = outputs[0][input_ids.shape[1]:]\n",
    "            response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "            # 4. –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ\n",
    "            try:\n",
    "                sentiment_score = int(response_text)\n",
    "                # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —á–∏—Å–ª–æ –≤ –¥–æ–ø—É—Å—Ç–∏–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ\n",
    "                if sentiment_score not in [-1, 0, 1]:\n",
    "                     print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ {sentiment_score} –¥–ª—è –ø–æ—Å—Ç–∞ {index}. –û—Ç–≤–µ—Ç: '{response_text}'. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é {default_sentiment}.\")\n",
    "                     results.append(default_sentiment)\n",
    "                else:\n",
    "                    results.append(sentiment_score)\n",
    "            except ValueError:\n",
    "                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ —á–∏—Å–ª–æ\n",
    "                print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞ {index}. –û—Ç–≤–µ—Ç: '{response_text}'. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é {default_sentiment}.\")\n",
    "                results.append(default_sentiment)\n",
    "\n",
    "        except Exception as e:\n",
    "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, OOM –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å—Ç–∞ {index}: {e}\")\n",
    "            print(f\"–¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞: {post_text[:100]}...\") # –ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞—á–∞–ª–æ –ø–æ—Å—Ç–∞\n",
    "            results.append(default_sentiment) # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É, –µ—Å–ª–∏ –æ—à–∏–±–∫–∏ —Å–≤—è–∑–∞–Ω—ã —Å –ø–µ—Ä–µ–≥—Ä—É–∑–∫–æ–π\n",
    "            # time.sleep(1) \n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∫ –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É\n",
    "    df[output_column] = results\n",
    "    print(\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
    "    return df\n",
    "\n",
    "# --- –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏ ---\n",
    "# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ model –∏ tokenizer –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ posts_llama_2000 —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
    "\n",
    "# –ö–æ–ø–∏—Ä—É–µ–º DataFrame, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª (—Ö–æ—Ä–æ—à–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞)\n",
    "df_processed = posts_llama_2000.copy() \n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é\n",
    "df_processed = classify_sentiment_llama(\n",
    "    df=df_processed,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=system_prompt,\n",
    "    text_column=\"processed_posts\", # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ\n",
    "    output_column=\"llama_3_1_sentiment\" # –ù–æ–≤–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏\n",
    ")\n",
    "\n",
    "# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---\n",
    "print(\"\\n–ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\")\n",
    "print(df_processed.head())\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤:\")\n",
    "print(df_processed['llama_3_1_sentiment'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import clear_output\n",
    "import time # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Ä–µ–º–µ–Ω–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-14B\" \n",
    "# –£–∫–∞–∑—ã–≤–∞–µ–º –ø–∞–º—è—Ç—å, —Ö–æ—Ç—è –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ø–æ–º–µ—Å—Ç–∏—Ç—å—Å—è –∏ –±–µ–∑ offload\n",
    "max_memory_map = {\n",
    "    0: \"14GiB\", \n",
    "    1: \"14GiB\"\n",
    "    # \"cpu\": \"...\" # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å, –Ω–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–µ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è\n",
    "}\n",
    "\n",
    "# --- –ó–∞–≥—Ä—É–∑–∫–∞ ---\n",
    "print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {MODEL_NAME}\")\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º trust_remote_code=True, —Ç.–∫. –º–æ–¥–µ–ª–∏ Qwen –º–æ–≥—É—Ç –µ–≥–æ —Ç—Ä–µ–±–æ–≤–∞—Ç—å\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\")\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º torch_dtype=\"auto\" –¥–ª—è FP8\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\", # –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ –¥–ª—è FP8\n",
    "    max_memory=max_memory_map,\n",
    "    trust_remote_code=True # –í–∞–∂–Ω–æ –¥–ª—è Qwen\n",
    ")\n",
    "clear_output()\n",
    "print(\"–ú–æ–¥–µ–ª—å Qwen3-14B –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:24:25.522332Z",
     "iopub.status.busy": "2025-05-02T18:24:25.521593Z",
     "iopub.status.idle": "2025-05-02T18:24:25.526853Z",
     "shell.execute_reply": "2025-05-02T18:24:25.526008Z",
     "shell.execute_reply.started": "2025-05-02T18:24:25.522305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"–¢—ã - –ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ –ø–æ—Å—Ç–æ–≤.\n",
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç –ø–æ –µ–≥–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–æ—Ä–≥–æ–≤–ª–∏ –∞–∫—Ü–∏—è–º–∏.\n",
    "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –û–î–ù–û –ß–ò–°–õ–û: 1 (–ø–æ–∫—É–ø–∫–∞/–±—ã—á–∏–π), 0 (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π), -1 (–ø—Ä–æ–¥–∞–∂–∞/–º–µ–¥–≤–µ–∂–∏–π)\n",
    "\n",
    "–í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã:\n",
    "\n",
    "–ü–æ—Å—Ç: \"–û—Ç–ª–∏—á–Ω—ã–π –æ—Ç—á–µ—Ç! –†–∞–∫–µ—Ç–∞ –≥–æ—Ç–æ–≤–∞ –∫ –≤–∑–ª–µ—Ç—É, –∑–∞–∫—É–ø–∞—é—Å—å –Ω–∞ –≤—Å—é –∫–æ—Ç–ª–µ—Ç—É #AAPL\"\n",
    "–û—Ç–≤–µ—Ç: 1\n",
    "\n",
    "–ü–æ—Å—Ç: \"–§–∏–∫—Å–∞–Ω—É–ª –ø—Ä–∏–±—ã–ª—å –ø–æ $GAZP. –†—ã–Ω–æ–∫ –≤—ã–≥–ª—è–¥–∏—Ç –ø–µ—Ä–µ–≥—Ä–µ—Ç—ã–º, –≤–æ–∑–º–æ–∂–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è.\"\n",
    "–û—Ç–≤–µ—Ç: -1\n",
    "\n",
    "–ü–æ—Å—Ç: \"–°–µ–≥–æ–¥–Ω—è –í–¢–ë –æ–ø—É–±–ª–∏–∫—É–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ –∫–≤–∞—Ä—Ç–∞–ª. –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å.\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "\n",
    "–ü–æ—Å—Ç: \"–ß—Ç–æ –¥—É–º–∞–µ—Ç–µ –ø—Ä–æ $SBER? –í—Ä–æ–¥–µ –∏ –¥–∏–≤—ã —Ö–æ—Ä–æ—à–∏–µ, –Ω–æ –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞ –¥–∞–≤–∏—Ç...\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "\n",
    "–ü–æ—Å—Ç: \"–ó–∞—à–æ—Ä—Ç–∏–ª —Å–±–µ—Ä –ø–µ—Ä–µ–¥ –æ—Ç—á–µ—Ç–æ–º\"\n",
    "–û—Ç–≤–µ—Ç: -1\n",
    "\n",
    "–ü–æ—Å—Ç: \"–ø–æ—Ä–∞ –¥–æ–∫—É–ø–∞—Ç—å —Å–±–µ—Ä–±–∞–Ω–∫ –ø–æ–∫–∞ –¥–µ—à–µ–≤—ã–π\"\n",
    "–û—Ç–≤–µ—Ç: 1\n",
    "\n",
    "–ü–æ—Å—Ç: \"–∫–∞–∫–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –ø–æ –≤—Ç–±?\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å —Ç–≤–æ—è –∑–∞–¥–∞—á–∞: –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ.\n",
    "\"\"\"\n",
    "\n",
    "# query = \"–±–µ—Ä—É —Å–±–µ—Ä –≤ —à–æ—Ä—Ç\"\n",
    "\n",
    "# # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–≤–æ–¥–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ Qwen ---\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": system_prompt},\n",
    "#     {\"role\": \"user\", \"content\": query}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:29:24.509224Z",
     "iopub.status.busy": "2025-05-02T18:29:24.508899Z",
     "iopub.status.idle": "2025-05-02T18:29:24.514643Z",
     "shell.execute_reply": "2025-05-02T18:29:24.513947Z",
     "shell.execute_reply.started": "2025-05-02T18:29:24.509200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"–¢—ã - –ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ –ø–æ—Å—Ç–æ–≤.\n",
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç –ø–æ –µ–≥–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–æ—Ä–≥–æ–≤–ª–∏ –∞–∫—Ü–∏—è–º–∏.\n",
    "\n",
    "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –ø—Ä–∞–≤–∏–ª–∞:\n",
    "*   **1 (–ü–æ–∫—É–ø–∫–∞/–ë—ã—á–∏–π):** –ü–æ—Å—Ç —è–≤–Ω–æ –≤—ã—Ä–∞–∂–∞–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –∫—É–ø–∏—Ç—å, —Ä–µ—à–µ–Ω–∏–µ –æ –ø–æ–∫—É–ø–∫–µ, —É–¥–µ—Ä–∂–∞–Ω–∏–µ –ª–æ–Ω–≥–∞ —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º —Ä–æ—Å—Ç–∞, –∏–ª–∏ –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å–∏–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –ø—Ä—è–º–æ —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ä–æ—Å—Ç —Ü–µ–Ω—ã –∞–∫—Ü–∏–∏. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞/–∏–¥–µ–∏: \"–∫—É–ø–∏–ª\", \"–¥–æ–∫—É–ø–∞—é\", \"–ª–æ–Ω–≥\", \"—Ä–∞–∫–µ—Ç–∞\", \"—Ä–æ—Å—Ç\", \"–ø—Ä–æ–±–æ–π –≤–≤–µ—Ä—Ö\", \"–æ—Ç—á–µ—Ç —Å—É–ø–µ—Ä\", \"–ø–æ—Ä–∞ –±—Ä–∞—Ç—å\", \"–¥–µ—Ä–∂–∞—Ç—å –¥–∞–ª—å—à–µ\", \"–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –µ—Å—Ç—å\".\n",
    "*   **-1 (–ü—Ä–æ–¥–∞–∂–∞/–ú–µ–¥–≤–µ–∂–∏–π):** –ü–æ—Å—Ç —è–≤–Ω–æ –≤—ã—Ä–∞–∂–∞–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–¥–∞—Ç—å, —Ä–µ—à–µ–Ω–∏–µ –æ –ø—Ä–æ–¥–∞–∂–µ, –æ—Ç–∫—Ä—ã—Ç–∏–µ/—É–¥–µ—Ä–∂–∞–Ω–∏–µ —à–æ—Ä—Ç–∞ —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º –ø–∞–¥–µ–Ω–∏—è, –∏–ª–∏ –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å–∏–ª—å–Ω—ã–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –ø—Ä—è–º–æ —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ —Ü–µ–Ω—ã –∞–∫—Ü–∏–∏. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞/–∏–¥–µ–∏: \"–ø—Ä–æ–¥–∞–ª\", \"—à–æ—Ä—Ç\", \"—Å–ª–∏–≤–∞—é\", \"–ø–∞–¥–µ–Ω–∏–µ\", \"–¥–Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\", \"–æ—Ç—á–µ—Ç –ø–ª–æ—Ö–æ–π\", \"–ø–æ—Ä–∞ –≤—ã—Ö–æ–¥–∏—Ç—å\", \"—Ñ–∏–∫—Å–∞—Ü–∏—è —É–±—ã—Ç–∫–∞\", \"–∫–æ—Ä—Ä–µ–∫—Ü–∏—è\".\n",
    "*   **0 (–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π):** –ü–æ—Å—Ç –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç —è–≤–Ω–æ–≥–æ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –ø–æ–∫—É–ø–∫—É –∏–ª–∏ –ø—Ä–æ–¥–∞–∂—É. –°—é–¥–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è:\n",
    "    *   –í–æ–ø—Ä–æ—Å—ã –æ —Ü–µ–Ω–µ –∏–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö (\"—á—Ç–æ –¥—É–º–∞–µ—Ç–µ?\", \"–∫—É–¥–∞ –ø–æ–π–¥–µ—Ç?\").\n",
    "    *   –ö–æ–Ω—Å—Ç–∞—Ç–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ–≤ –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –±–µ–∑ —è–≤–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ü–µ–Ω—É (\"–≤—ã—à–µ–ª –æ—Ç—á–µ—Ç\", \"—Å–µ–≥–æ–¥–Ω—è –¥–∏–≤–≥—ç–ø\").\n",
    "    *   –°–º–µ—à–∞–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏–ª–∏ —Å–æ–º–Ω–µ–Ω–∏—è (\"–≤—Ä–æ–¥–µ —Ä–∞—Å—Ç–µ—Ç, –Ω–æ —Å—Ç—Ä–∞—à–Ω–æ\", \"—Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã..., —Å –¥—Ä—É–≥–æ–π...\").\n",
    "    *   –û–±—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –¥–µ–π—Å—Ç–≤–∏—é.\n",
    "    *   –§–∏–∫—Å–∞—Ü–∏—è –ø—Ä–∏–±—ã–ª–∏ –∏–ª–∏ —É–±—ã—Ç–∫–∞ *–±–µ–∑ —è–≤–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞* –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è (\"–∑–∞–∫—Ä—ã–ª –ø–æ–∑–∏—Ü–∏—é\", \"–≤—ã—à–µ–ª –≤ –Ω–æ–ª—å\").\n",
    "    *   –ù–µ—è—Å–Ω—ã–µ –∏–ª–∏ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä—ã:\n",
    "–ü–æ—Å—Ç: \"–û—Ç–ª–∏—á–Ω—ã–π –æ—Ç—á–µ—Ç! –†–∞–∫–µ—Ç–∞ –≥–æ—Ç–æ–≤–∞ –∫ –≤–∑–ª–µ—Ç—É, –∑–∞–∫—É–ø–∞—é—Å—å –Ω–∞ –≤—Å—é –∫–æ—Ç–ª–µ—Ç—É #AAPL\"\n",
    "–û—Ç–≤–µ—Ç: 1\n",
    "–ü–æ—Å—Ç: \"–§–∏–∫—Å–∞–Ω—É–ª –ø—Ä–∏–±—ã–ª—å –ø–æ $GAZP. –†—ã–Ω–æ–∫ –≤—ã–≥–ª—è–¥–∏—Ç –ø–µ—Ä–µ–≥—Ä–µ—Ç—ã–º, –≤–æ–∑–º–æ–∂–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è.\"\n",
    "–û—Ç–≤–µ—Ç: -1\n",
    "–ü–æ—Å—Ç: \"–°–µ–≥–æ–¥–Ω—è –í–¢–ë –æ–ø—É–±–ª–∏–∫—É–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ –∫–≤–∞—Ä—Ç–∞–ª. –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å.\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "–ü–æ—Å—Ç: \"–ß—Ç–æ –¥—É–º–∞–µ—Ç–µ –ø—Ä–æ $SBER? –í—Ä–æ–¥–µ –∏ –¥–∏–≤—ã —Ö–æ—Ä–æ—à–∏–µ, –Ω–æ –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞ –¥–∞–≤–∏—Ç...\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "–ü–æ—Å—Ç: \"–ó–∞—à–æ—Ä—Ç–∏–ª —Å–±–µ—Ä –ø–µ—Ä–µ–¥ –æ—Ç—á–µ—Ç–æ–º\"\n",
    "–û—Ç–≤–µ—Ç: -1\n",
    "–ü–æ—Å—Ç: \"–ø–æ—Ä–∞ –¥–æ–∫—É–ø–∞—Ç—å —Å–±–µ—Ä–±–∞–Ω–∫ –ø–æ–∫–∞ –¥–µ—à–µ–≤—ã–π\"\n",
    "–û—Ç–≤–µ—Ç: 1\n",
    "–ü–æ—Å—Ç: \"–∫–∞–∫–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –ø–æ –≤—Ç–±?\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "–ü–æ—Å—Ç: \"–ó–∞–∫—Ä—ã–ª –ª–æ–Ω–≥ –ø–æ –õ—É–∫–æ–π–ª—É –≤ –ø–ª—é—Å, –ø–æ–∫–∞ –ø–æ–Ω–∞–±–ª—é–¥–∞—é —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã\"\n",
    "–û—Ç–≤–µ—Ç: 0\n",
    "\n",
    "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –û–î–ù–û —á–∏—Å–ª–æ: 1, 0 –∏–ª–∏ -1.\n",
    "\n",
    "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —á–∏—Å–ª–æ–≤–æ–π –æ—Ç–≤–µ—Ç:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:31:01.435235Z",
     "iopub.status.busy": "2025-05-02T18:31:01.434547Z",
     "iopub.status.idle": "2025-05-02T18:31:01.438367Z",
     "shell.execute_reply": "2025-05-02T18:31:01.437832Z",
     "shell.execute_reply.started": "2025-05-02T18:31:01.435208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"–¢—ã - –ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ –ø–æ—Å—Ç–æ–≤.\n",
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç –ø–æ –µ–≥–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–æ—Ä–≥–æ–≤–ª–∏ –∞–∫—Ü–∏—è–º–∏.\n",
    "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –û–î–ù–û –ß–ò–°–õ–û: 1 (–ø–æ–∫—É–ø–∞–µ–º –∞–∫—Ç–∏–≤/–±—ã—á–∏–π), 0 (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π), -1 (–ø—Ä–æ–¥–∞–µ–º –∞–∫—Ç–∏–≤ /–º–µ–¥–≤–µ–∂–∏–π)\n",
    "\n",
    "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —à–∞–±–ª–æ–Ω —á–∞—Ç–∞ Qwen, –æ—Ç–∫–ª—é—á–∞–µ–º \"thinking\"\n",
    "# tokenize=True –≤–µ—Ä–Ω–µ—Ç input_ids –∏ attention_mask —Å—Ä–∞–∑—É\n",
    "model_inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False, # –û—Ç–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –∑–∞–¥–∞—á–∏\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "print(f\"\\n–ó–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏:\\nSystem: {system_prompt}\\nUser: {query}\")\n",
    "print(\"\\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ---\n",
    "# –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å eos_token_id –ø—Ä–∏ enable_thinking=False –∏ do_sample=False, \n",
    "# –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è —Å–∞–º–∞ –∏–ª–∏ –Ω–∞ max_new_tokens\n",
    "outputs = model.generate(\n",
    "    model_inputs, # –ü–µ—Ä–µ–¥–∞–µ–º input_ids –∏ attention_mask (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "    max_new_tokens=10, # –ú–∞–ª–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞\n",
    "    do_sample=False,   # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥\n",
    "    pad_token_id=tokenizer.eos_token_id \n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {end_time - start_time:.2f} —Å–µ–∫\")\n",
    "\n",
    "# --- –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ ---\n",
    "# –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —á–∞—Å—Ç—å\n",
    "# model_inputs –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º input_ids\n",
    "input_ids_len = model_inputs['input_ids'].shape[1] if isinstance(model_inputs, dict) else model_inputs.shape[1]\n",
    "response_ids = outputs[0][input_ids_len:] \n",
    "response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "print(f\"\\n–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (—Å—ã—Ä–æ–π):\")\n",
    "print(response_text)\n",
    "\n",
    "# –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ\n",
    "try:\n",
    "    sentiment_score = int(response_text)\n",
    "    if sentiment_score not in [-1, 0, 1]:\n",
    "        print(f\"\\n–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ {sentiment_score}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 0.\")\n",
    "        sentiment_score = 0\n",
    "    print(f\"\\n–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞: {sentiment_score}\")\n",
    "except ValueError:\n",
    "    print(f\"\\n–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ –æ—Ç–≤–µ—Ç–∞: '{response_text}'. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 0.\")\n",
    "    sentiment_score = 0 # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:21:31.572162Z",
     "iopub.status.busy": "2025-05-02T18:21:31.571606Z",
     "iopub.status.idle": "2025-05-02T18:21:31.715171Z",
     "shell.execute_reply": "2025-05-02T18:21:31.714581Z",
     "shell.execute_reply.started": "2025-05-02T18:21:31.572139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>processed_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78592a62-93f9-4940-b914-a6cb8baafaff</td>\n",
       "      <td>ü™ì {$SGZH} ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∞—é—Ç –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47ed3f81-fead-4d6e-9186-d2b21de56e4c</td>\n",
       "      <td>–ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Ç–∞–∫–∏—Ö –∞–∫—Ç–∏–≤–æ–≤ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01d56071-766d-40a1-801c-4572e703fdc6</td>\n",
       "      <td>Market Power üó£ –ø—Ä–æ {$SBER}:\\n\\n\"–°–±–µ—Ä –ø—Ä–µ–≤–æ—Å—Ö–æ–¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761e88a9-0b4e-4a46-b569-ca92762b78b4</td>\n",
       "      <td>‚Ä¢29.08.2023 {$SGZH} \\n–°–µ–≥–µ–∂–∞ –ì—Ä—É–ø–ø –æ–ø—É–±–ª–∏–∫—É–µ—Ç ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66369560-83a0-4456-80de-2ba0239b4e1f</td>\n",
       "      <td>{$SBER}\\n–¶–ë –≥–æ—Ç–æ–≤ –∏–¥—Ç–∏ –Ω–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–µ –º–µ—Ä—ã, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>c91e9965-9574-463d-86f2-70d472d4f3a9</td>\n",
       "      <td>{$LKOH} \\n‚ÄºÔ∏è–î–∞–≤–∞–π—Ç–µ —Å—Ä–∞–≤–Ω–∏–º –∞–∫—Ü–∏–∏ –Ω–æ–º–µ—Ä –æ–¥–∏–Ω 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5</td>\n",
       "      <td>{$SBER} )))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>faf7264b-67fe-4d5d-998c-9e2c026f3b76</td>\n",
       "      <td>{$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>16c1315f-d62e-4412-8faa-48542fe4b437</td>\n",
       "      <td>{$SGZH} \\nÔªø–°–¥—É–≤–∞–µ—Ç—Å—è –º—ã–ª—å–Ω—ã–π –ø—É–∑—ã—Ä—å, —á—Ç–æ –∏ —Ç—Ä–µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>b4892d9b-3290-4b62-b494-293487fb3f2d</td>\n",
       "      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ –Ω–∞—à —Ä—ã–Ω–æ–∫ –¥–∞–≤–Ω–æ —É–∂–µ –ø—Ä–∏–≤—ã–∫ –∫ —Å–∞...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   post_id  \\\n",
       "0     78592a62-93f9-4940-b914-a6cb8baafaff   \n",
       "1     47ed3f81-fead-4d6e-9186-d2b21de56e4c   \n",
       "2     01d56071-766d-40a1-801c-4572e703fdc6   \n",
       "3     761e88a9-0b4e-4a46-b569-ca92762b78b4   \n",
       "4     66369560-83a0-4456-80de-2ba0239b4e1f   \n",
       "...                                    ...   \n",
       "2995  c91e9965-9574-463d-86f2-70d472d4f3a9   \n",
       "2996  e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5   \n",
       "2997  faf7264b-67fe-4d5d-998c-9e2c026f3b76   \n",
       "2998  16c1315f-d62e-4412-8faa-48542fe4b437   \n",
       "2999  b4892d9b-3290-4b62-b494-293487fb3f2d   \n",
       "\n",
       "                                        processed_posts  \n",
       "0     ü™ì {$SGZH} ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∞—é—Ç –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏...  \n",
       "1     –ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Ç–∞–∫–∏—Ö –∞–∫—Ç–∏–≤–æ–≤ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ...  \n",
       "2     Market Power üó£ –ø—Ä–æ {$SBER}:\\n\\n\"–°–±–µ—Ä –ø—Ä–µ–≤–æ—Å—Ö–æ–¥...  \n",
       "3     ‚Ä¢29.08.2023 {$SGZH} \\n–°–µ–≥–µ–∂–∞ –ì—Ä—É–ø–ø –æ–ø—É–±–ª–∏–∫—É–µ—Ç ...  \n",
       "4     {$SBER}\\n–¶–ë –≥–æ—Ç–æ–≤ –∏–¥—Ç–∏ –Ω–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–µ –º–µ—Ä—ã, ...  \n",
       "...                                                 ...  \n",
       "2995  {$LKOH} \\n‚ÄºÔ∏è–î–∞–≤–∞–π—Ç–µ —Å—Ä–∞–≤–Ω–∏–º –∞–∫—Ü–∏–∏ –Ω–æ–º–µ—Ä –æ–¥–∏–Ω 1...  \n",
       "2996                                        {$SBER} )))  \n",
       "2997  {$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...  \n",
       "2998  {$SGZH} \\nÔªø–°–¥—É–≤–∞–µ—Ç—Å—è –º—ã–ª—å–Ω—ã–π –ø—É–∑—ã—Ä—å, —á—Ç–æ –∏ —Ç—Ä–µ...  \n",
       "2999  –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ –Ω–∞—à —Ä—ã–Ω–æ–∫ –¥–∞–≤–Ω–æ —É–∂–µ –ø—Ä–∏–≤—ã–∫ –∫ —Å–∞...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_qwen_2000 = pd.read_csv(\"/kaggle/input/qwen-dataset/data_qwen_raw.csv\")\n",
    "posts_qwen_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:31:38.910491Z",
     "iopub.status.busy": "2025-05-02T18:31:38.909835Z",
     "iopub.status.idle": "2025-05-02T19:10:32.341857Z",
     "shell.execute_reply": "2025-05-02T19:10:32.340995Z",
     "shell.execute_reply.started": "2025-05-02T18:31:38.910458Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É 3000 –ø–æ—Å—Ç–æ–≤ —Å –º–æ–¥–µ–ª—å—é Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è Qwen:   0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è Qwen: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [38:53<00:00,  1.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ 2333.41 —Å–µ–∫ (0.778 —Å–µ–∫/–ø–æ—Å—Ç).\n",
      "\n",
      "–ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Qwen:\n",
      "                                post_id  \\\n",
      "0  78592a62-93f9-4940-b914-a6cb8baafaff   \n",
      "1  47ed3f81-fead-4d6e-9186-d2b21de56e4c   \n",
      "2  01d56071-766d-40a1-801c-4572e703fdc6   \n",
      "3  761e88a9-0b4e-4a46-b569-ca92762b78b4   \n",
      "4  66369560-83a0-4456-80de-2ba0239b4e1f   \n",
      "\n",
      "                                     processed_posts  \\\n",
      "0  ü™ì {$SGZH} ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∞—é—Ç –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏...   \n",
      "1  –ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Ç–∞–∫–∏—Ö –∞–∫—Ç–∏–≤–æ–≤ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ...   \n",
      "2  Market Power üó£ –ø—Ä–æ {$SBER}:\\n\\n\"–°–±–µ—Ä –ø—Ä–µ–≤–æ—Å—Ö–æ–¥...   \n",
      "3  ‚Ä¢29.08.2023 {$SGZH} \\n–°–µ–≥–µ–∂–∞ –ì—Ä—É–ø–ø –æ–ø—É–±–ª–∏–∫—É–µ—Ç ...   \n",
      "4  {$SBER}\\n–¶–ë –≥–æ—Ç–æ–≤ –∏–¥—Ç–∏ –Ω–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–µ –º–µ—Ä—ã, ...   \n",
      "\n",
      "   qwen_14b_instruct_sentiment  \n",
      "0                           -1  \n",
      "1                            0  \n",
      "2                            1  \n",
      "3                            0  \n",
      "4                           -1  \n",
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ Qwen:\n",
      "qwen_14b_instruct_sentiment\n",
      " 0    1050\n",
      "-1    1024\n",
      " 1     926\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def classify_sentiment_qwen_batch( # –ù–µ–º–Ω–æ–≥–æ –∏–∑–º–µ–Ω–∏–ª –∏–º—è –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏\n",
    "    df: pd.DataFrame,\n",
    "    model, \n",
    "    tokenizer, \n",
    "    system_prompt: str,\n",
    "    text_column: str = \"processed_posts\",\n",
    "    output_column: str = \"qwen_sentiment\", # –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "    max_new_tokens: int = 10,\n",
    "    default_sentiment: int = 0, \n",
    "    batch_size: int = 1 # –û—Å—Ç–∞–≤–ª—è–µ–º 1 –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, —Ç.–∫. –±–∞—Ç—á–∏–Ω–≥ —Ç—Ä–µ–±—É–µ—Ç –ø–∞–¥–¥–∏–Ω–≥–∞\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç –ø–æ—Å—Ç–æ–≤ –≤ DataFrame —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ Qwen.\n",
    "    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–¥–∞—á–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ apply_chat_template –Ω–∞–ø—Ä—è–º—É—é –≤ generate.\n",
    "\n",
    "    Args:\n",
    "        df: –í—Ö–æ–¥–Ω–æ–π DataFrame.\n",
    "        model: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Qwen.\n",
    "        tokenizer: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä Qwen.\n",
    "        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏.\n",
    "        text_column: –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º –ø–æ—Å—Ç–æ–≤.\n",
    "        output_column: –ò–º—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.\n",
    "        max_new_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "        default_sentiment: –ó–Ω–∞—á–µ–Ω–∏–µ, –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º–æ–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞.\n",
    "        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–æ–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 1).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–æ–π output_column.\n",
    "    \"\"\"\n",
    "    if batch_size != 1:\n",
    "        raise NotImplementedError(\"Batch size > 1 requires padding and attention mask handling, currently not implemented here.\")\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    print(f\"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(df)} –ø–æ—Å—Ç–æ–≤ —Å –º–æ–¥–µ–ª—å—é Qwen...\")\n",
    "    start_total_time = time.time()\n",
    "    \n",
    "    # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –ø–æ—Å—Ç–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è Qwen\"):\n",
    "        post_text = row[text_column]\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "        if not isinstance(post_text, str) or not post_text.strip():\n",
    "            results.append(default_sentiment)\n",
    "            continue\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": post_text}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # 1. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (—Å—Ä–∞–∑—É –Ω–∞ GPU)\n",
    "            #    –≠—Ç–∞ —á–∞—Å—Ç—å —Ç–µ–ø–µ—Ä—å –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –≤–∞—à–µ–º —Ä–∞–±–æ—á–µ–º –≤–∞—Ä–∏–∞–Ω—Ç–µ\n",
    "            torch.cuda.empty_cache() \n",
    "            model_inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                enable_thinking=False, \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "            \n",
    "            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏–Ω—É –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –î–û –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "            # –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è input_ids_len —Ç–µ–ø–µ—Ä—å –∑–¥–µ—Å—å\n",
    "            if isinstance(model_inputs, dict):\n",
    "                input_ids_len = model_inputs['input_ids'].shape[1]\n",
    "            elif hasattr(model_inputs, 'shape'): # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–µ–Ω–∑–æ—Ä –∏–ª–∏ –ø–æ–¥–æ–±–Ω—ã–π –æ–±—ä–µ–∫—Ç\n",
    "                 input_ids_len = model_inputs.shape[1]\n",
    "            else:\n",
    "                # –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø, –ø—ã—Ç–∞–µ–º—Å—è —É–≥–∞–¥–∞—Ç—å –∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º\n",
    "                print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å input_ids_len –¥–ª—è –ø–æ—Å—Ç–∞ {index}. –¢–∏–ø: {type(model_inputs)}. –ü—Ä–æ–ø—É—Å–∫.\")\n",
    "                results.append(default_sentiment)\n",
    "                continue\n",
    "\n",
    "            # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (–ø–µ—Ä–µ–¥–∞–µ–º model_inputs –Ω–∞–ø—Ä—è–º—É—é)\n",
    "            outputs = model.generate(\n",
    "                model_inputs, # –ü–µ—Ä–µ–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –Ω–∞–ø—Ä—è–º—É—é\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.eos_token_id \n",
    "            )\n",
    "            # 3. –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "            response_ids = outputs[0][input_ids_len:] # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–Ω–µ–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—É—é –¥–ª–∏–Ω—É\n",
    "            response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "            # 4. –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞\n",
    "            try:\n",
    "                sentiment_score = int(response_text)\n",
    "                if sentiment_score not in [-1, 0, 1]:\n",
    "                     # print(f\"–ü—Ä–µ–¥—É–ø—Ä: –ù–µ–∫–æ—Ä—Ä. —á–∏—Å–ª–æ {sentiment_score} –¥–ª—è –ø–æ—Å—Ç–∞ {index}. –û—Ç–≤–µ—Ç: '{response_text}'.\") # –û—Ç–ª–∞–¥–∫–∞\n",
    "                     results.append(default_sentiment)\n",
    "                else:\n",
    "                    results.append(sentiment_score)\n",
    "            except ValueError:\n",
    "                # print(f\"–ü—Ä–µ–¥—É–ø—Ä: –ù–µ —á–∏—Å–ª–æ –¥–ª—è –ø–æ—Å—Ç–∞ {index}. –û—Ç–≤–µ—Ç: '{response_text}'.\") # –û—Ç–ª–∞–¥–∫–∞\n",
    "                results.append(default_sentiment)\n",
    "\n",
    "        except Exception as e:\n",
    "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, OOM –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)\n",
    "            print(f\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å—Ç–∞ {index}: {e}\")\n",
    "            print(f\"–¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞: {post_text[:100]}...\") \n",
    "            results.append(default_sentiment) # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "            # time.sleep(1) # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–∞—É–∑—É –ø—Ä–∏ —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–∫–∞—Ö\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∫ –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É\n",
    "    df[output_column] = results\n",
    "    \n",
    "    end_total_time = time.time()\n",
    "    total_time = end_total_time - start_total_time\n",
    "    avg_time = total_time / len(df) if len(df) > 0 else 0\n",
    "    print(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.2f} —Å–µ–∫ ({avg_time:.3f} —Å–µ–∫/–ø–æ—Å—Ç).\")\n",
    "    return df\n",
    "\n",
    "# --- –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏ ---\n",
    "# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ model (–Ω–∞–ø—Ä–∏–º–µ—Ä, Qwen/Qwen3-14B-Instruct) –∏ tokenizer –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n",
    "# –∏ DataFrame posts_llama_2000 —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
    "\n",
    "df_for_qwen_processing = posts_qwen_2000.copy() \n",
    "\n",
    "df_classified_qwen = classify_sentiment_qwen_batch(\n",
    "    df=df_for_qwen_processing,\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    system_prompt=system_prompt,\n",
    "    text_column=\"processed_posts\", \n",
    "    output_column=\"qwen_14b_instruct_sentiment\" # –£–∫–∞–∂–∏—Ç–µ –∂–µ–ª–∞–µ–º–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏\n",
    ")\n",
    "\n",
    "# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---\n",
    "print(\"\\n–ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Qwen:\")\n",
    "print(df_classified_qwen.head())\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ Qwen:\")\n",
    "print(df_classified_qwen['qwen_14b_instruct_sentiment'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:18:32.729080Z",
     "iopub.status.busy": "2025-05-02T19:18:32.728770Z",
     "iopub.status.idle": "2025-05-02T19:18:32.746062Z",
     "shell.execute_reply": "2025-05-02T19:18:32.745469Z",
     "shell.execute_reply.started": "2025-05-02T19:18:32.729054Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>processed_posts</th>\n",
       "      <th>qwen_14b_instruct_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78592a62-93f9-4940-b914-a6cb8baafaff</td>\n",
       "      <td>ü™ì {$SGZH} ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∞—é—Ç –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47ed3f81-fead-4d6e-9186-d2b21de56e4c</td>\n",
       "      <td>–ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Ç–∞–∫–∏—Ö –∞–∫—Ç–∏–≤–æ–≤ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01d56071-766d-40a1-801c-4572e703fdc6</td>\n",
       "      <td>Market Power üó£ –ø—Ä–æ {$SBER}:\\n\\n\"–°–±–µ—Ä –ø—Ä–µ–≤–æ—Å—Ö–æ–¥...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761e88a9-0b4e-4a46-b569-ca92762b78b4</td>\n",
       "      <td>‚Ä¢29.08.2023 {$SGZH} \\n–°–µ–≥–µ–∂–∞ –ì—Ä—É–ø–ø –æ–ø—É–±–ª–∏–∫—É–µ—Ç ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66369560-83a0-4456-80de-2ba0239b4e1f</td>\n",
       "      <td>{$SBER}\\n–¶–ë –≥–æ—Ç–æ–≤ –∏–¥—Ç–∏ –Ω–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–µ –º–µ—Ä—ã, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>c91e9965-9574-463d-86f2-70d472d4f3a9</td>\n",
       "      <td>{$LKOH} \\n‚ÄºÔ∏è–î–∞–≤–∞–π—Ç–µ —Å—Ä–∞–≤–Ω–∏–º –∞–∫—Ü–∏–∏ –Ω–æ–º–µ—Ä –æ–¥–∏–Ω 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5</td>\n",
       "      <td>{$SBER} )))</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>faf7264b-67fe-4d5d-998c-9e2c026f3b76</td>\n",
       "      <td>{$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>16c1315f-d62e-4412-8faa-48542fe4b437</td>\n",
       "      <td>{$SGZH} \\nÔªø–°–¥—É–≤–∞–µ—Ç—Å—è –º—ã–ª—å–Ω—ã–π –ø—É–∑—ã—Ä—å, —á—Ç–æ –∏ —Ç—Ä–µ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>b4892d9b-3290-4b62-b494-293487fb3f2d</td>\n",
       "      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ –Ω–∞—à —Ä—ã–Ω–æ–∫ –¥–∞–≤–Ω–æ —É–∂–µ –ø—Ä–∏–≤—ã–∫ –∫ —Å–∞...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   post_id  \\\n",
       "0     78592a62-93f9-4940-b914-a6cb8baafaff   \n",
       "1     47ed3f81-fead-4d6e-9186-d2b21de56e4c   \n",
       "2     01d56071-766d-40a1-801c-4572e703fdc6   \n",
       "3     761e88a9-0b4e-4a46-b569-ca92762b78b4   \n",
       "4     66369560-83a0-4456-80de-2ba0239b4e1f   \n",
       "...                                    ...   \n",
       "2995  c91e9965-9574-463d-86f2-70d472d4f3a9   \n",
       "2996  e88390b2-a5bb-4403-b6bc-4ac5a8dc2eb5   \n",
       "2997  faf7264b-67fe-4d5d-998c-9e2c026f3b76   \n",
       "2998  16c1315f-d62e-4412-8faa-48542fe4b437   \n",
       "2999  b4892d9b-3290-4b62-b494-293487fb3f2d   \n",
       "\n",
       "                                        processed_posts  \\\n",
       "0     ü™ì {$SGZH} ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∞—é—Ç –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏...   \n",
       "1     –ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Ç–∞–∫–∏—Ö –∞–∫—Ç–∏–≤–æ–≤ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ...   \n",
       "2     Market Power üó£ –ø—Ä–æ {$SBER}:\\n\\n\"–°–±–µ—Ä –ø—Ä–µ–≤–æ—Å—Ö–æ–¥...   \n",
       "3     ‚Ä¢29.08.2023 {$SGZH} \\n–°–µ–≥–µ–∂–∞ –ì—Ä—É–ø–ø –æ–ø—É–±–ª–∏–∫—É–µ—Ç ...   \n",
       "4     {$SBER}\\n–¶–ë –≥–æ—Ç–æ–≤ –∏–¥—Ç–∏ –Ω–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–µ –º–µ—Ä—ã, ...   \n",
       "...                                                 ...   \n",
       "2995  {$LKOH} \\n‚ÄºÔ∏è–î–∞–≤–∞–π—Ç–µ —Å—Ä–∞–≤–Ω–∏–º –∞–∫—Ü–∏–∏ –Ω–æ–º–µ—Ä –æ–¥–∏–Ω 1...   \n",
       "2996                                        {$SBER} )))   \n",
       "2997  {$SBER} {$LKOH} {$T} {$MGNT} {$VTBR} {$GMKN} \\...   \n",
       "2998  {$SGZH} \\nÔªø–°–¥—É–≤–∞–µ—Ç—Å—è –º—ã–ª—å–Ω—ã–π –ø—É–∑—ã—Ä—å, —á—Ç–æ –∏ —Ç—Ä–µ...   \n",
       "2999  –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ –Ω–∞—à —Ä—ã–Ω–æ–∫ –¥–∞–≤–Ω–æ —É–∂–µ –ø—Ä–∏–≤—ã–∫ –∫ —Å–∞...   \n",
       "\n",
       "      qwen_14b_instruct_sentiment  \n",
       "0                              -1  \n",
       "1                               0  \n",
       "2                               1  \n",
       "3                               0  \n",
       "4                              -1  \n",
       "...                           ...  \n",
       "2995                            1  \n",
       "2996                            0  \n",
       "2997                            0  \n",
       "2998                           -1  \n",
       "2999                           -1  \n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:24:51.481898Z",
     "iopub.status.busy": "2025-05-02T18:24:51.481585Z",
     "iopub.status.idle": "2025-05-02T18:24:51.488260Z",
     "shell.execute_reply": "2025-05-02T18:24:51.487431Z",
     "shell.execute_reply.started": "2025-05-02T18:24:51.481872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ü™ì {$SGZH} ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∞—é—Ç –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–±–∏—Ä–∂–∏. –ï–µ –º–µ—Å—Ç–æ –∑–∞–π–º–µ—Ç üì± $YDEX.',\n",
       "       '–ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Ç–∞–∫–∏—Ö –∞–∫—Ç–∏–≤–æ–≤ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –º–Ω–æ–≥–æ, –≤–µ–¥—å –æ—Å–µ–Ω—å –æ–±—ã—á–Ω–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∑–∞–º–µ—Ç–Ω—ã–º –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–º —Å–µ–∑–æ–Ω–æ–º. –î–æ –∫–æ–Ω—Ü–∞ –≥–æ–¥–∞ –æ–∫–æ–ª–æ 20 —ç–º–∏—Ç–µ–Ω—Ç–æ–≤, –≤ —Ç–æ–º —á–∏—Å–ª–µ {$LKOH} –õ–£–ö–û–ô–õ, {$RTKM} –†–æ—Å—Ç–µ–ª–µ–∫–æ–º, {$GMKN} –ù–æ—Ä–Ω–∏–∫–µ–ª—å –∏ {$PHOR} –§–æ—Å–∞–≥—Ä–æ, –ø–ª–∞–Ω–∏—Ä—É—é—Ç –≤—ã–ø–ª–∞—Ç–∏—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥.',\n",
       "       'Market Power üó£ –ø—Ä–æ {$SBER}:\\n\\n\"–°–±–µ—Ä –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å–µ–±—è\\n–ë–æ–ª—å—à–æ–π –∑–µ–ª–µ–Ω—ã–π –±–∞–Ω–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª –æ—Ç—á–µ—Ç –∑–∞ 2 –∫–≤–∞—Ä—Ç–∞–ª –∏ 1 –ø–æ–ª—É–≥–æ–¥–∏–µ\\n\\n–°–±–µ—Ä\\n–ú–°–∞—Ä = ‚ÇΩ6 —Ç—Ä–ª–Ω\\n\\nüìä–ò—Ç–æ–≥–∏ 2 –∫–≤–∞—Ä—Ç–∞–ª–∞\\n- –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –¥–æ—Ö–æ–¥—ã: ‚ÇΩ598 –º–ª—Ä–¥;\\n- –∫–æ–º–∏—Å—Å–∏–æ–Ω–Ω—ã–µ –¥–æ—Ö–æ–¥—ã: ‚ÇΩ187 –º–ª—Ä–¥;\\n- —á–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å: ‚ÇΩ380 –º–ª—Ä–¥;\\n- —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–ø–∏—Ç–∞–ª–∞: 26%;\\n- –∞–∫—Ç–∏–≤–Ω—ã–µ —Ñ–∏–∑–ª–∏—Ü–∞: 107 –º–ª–Ω (+1% —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞);\\n- –µ–∂–µ–º–µ—Å—è—á–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –°–±–µ—Ä–û–Ω–ª–∞–π–Ω: 80 –º–ª–Ω (+1,5% —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞);\\n- —Ä–æ–∑–Ω–∏—á–Ω—ã–π –∫—Ä–µ–¥–∏—Ç–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å: ‚ÇΩ14 —Ç—Ä–ª–Ω (+12% —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞);\\n- –∏–ø–æ—Ç–µ—á–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å: ‚ÇΩ8,5 —Ç—Ä–ª–Ω (+12% —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞).\\n\\n ‚ùóÔ∏è–°—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ –ø—Ä–∏–±—ã–ª—å –∑–∞ 2 –∫–≤–∞—Ä—Ç–∞–ª –æ–∫–∞–∑–∞–ª–∞—Å—å –¥–∞–∂–µ –≤—ã—à–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å-–ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Ä—ã–Ω–∫–∞. –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –∑–∞ –ø–æ–ª–≥–æ–¥–∞ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ ‚ÇΩ738 –º–ª—Ä–¥. \\n\\nü•∏–†–æ—Å—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –¥–æ—Ö–æ–¥–æ–≤ –±–∞–Ω–∫ –æ–±—ä—è—Å–Ω—è–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º –æ–±—ä–µ–º–∞ —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –∞–∫—Ç–∏–≤–æ–≤ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –±–∏–∑–Ω–µ—Å–∞. –ö–æ–º–∏—Å—Å–∏–æ–Ω–Ω—ã–µ –∂–µ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ —Ñ–æ–Ω–µ —Ä–æ—Å—Ç–∞ –¥–æ—Ö–æ–¥–æ–≤ –æ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π —Å –±–∞–Ω–∫–æ–≤—Å–∫–∏–º–∏ –∫–∞—Ä—Ç–∞–º–∏ –∏ —Ä–∞—Å—á–µ—Ç–Ω–æ-–∫–∞—Å—Å–æ–≤–æ–≥–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è.\"',\n",
       "       '‚Ä¢29.08.2023 {$SGZH} \\n–°–µ–≥–µ–∂–∞ –ì—Ä—É–ø–ø –æ–ø—É–±–ª–∏–∫—É–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –ú–°–§–û –∑–∞ I –ø–æ–ª—É–≥–æ–¥–∏–µ 2023 –≥.',\n",
       "       '{$SBER}\\n–¶–ë –≥–æ—Ç–æ–≤ –∏–¥—Ç–∏ –Ω–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–µ –º–µ—Ä—ã, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –∏–Ω—Ñ–ª—è—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–µ–Ω—å 4% –≤ 2025 –≥–æ–¥—É, ‚Äî –≥–ª–∞–≤–∞ –¶–ë –≠–ª—å–≤–∏—Ä–∞ –ù–∞–±–∏—É–ª–ª–∏–Ω–∞. –í —Ç–æ–º —á–∏—Å–ª–µ, –Ω–µ –∏—Å–∫–ª—é—á–∞–µ—Ç—Å—è –¥–∞–ª—å–Ω–µ–π—à–µ–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–π —Å—Ç–∞–≤–∫–∏.',\n",
       "       '{$SBER} –¥–∏–≤–∏–¥–µ–Ω–¥—ã)',\n",
       "       '–õ–£–ö–û–ô–õ. –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞—Ä–∞—Å—Ç–∞–µ—Ç\\n\\n–í –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–æ—Ä–≥–æ–≤—ã–π –¥–µ–Ω—å –∞–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –õ–£–ö–û–ô–õ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 0,51%, –∑–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–æ—à–ª–æ –Ω–∞ –æ—Ç–º–µ—Ç–∫–µ 4342 —Ä—É–±. –ë—É–º–∞–≥–∞ –≤—ã–≥–ª—è–¥–µ–ª–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ä—ã–Ω–∫–∞, –ø—Ä–∏–±–∞–≤–∏–≤—à–µ–≥–æ 0,74%. –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ –∞–∫—Ü–∏–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º —Ä—ã–Ω–∫–µ —Å–æ—Å—Ç–∞–≤–∏–ª 1,8 –º–ª—Ä–¥ —Ä—É–±. –ø—Ä–∏ —Å—Ä–µ–¥–Ω–µ–º –∑–∞ –º–µ—Å—è—Ü 1,8 –º–ª—Ä–¥ —Ä—É–±.\\n\\n–ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∞:\\n‚Ä¢–ë—É–º–∞–≥–∏ –õ–£–ö–û–ô–õ–∞ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —Ä–∞—Å—Ç–∏, –Ω–∞–∫–∞–ø–ª–∏–≤–∞—è –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å. –ü–æ –æ—Å—Ü–∏–ª–ª—è—Ç–æ—Ä—É RSI –Ω–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ D1 –æ–Ω–∞ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç—Å—è —É–∂–µ —Ç—Ä–µ—Ç–∏–π –¥–µ–Ω—å –ø–æ–¥—Ä—è–¥. –ß–µ–º –±–ª–∏–∂–µ –≤—ã—Ö–æ–¥–Ω—ã–µ, —Ç–µ–º –≤—ã—à–µ —à–∞–Ω—Å—ã, —á—Ç–æ —Ç–∞–∫–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —É—Å–∏–ª–µ–Ω–∏—é —Ä–∞—Å–ø—Ä–æ–¥–∞–∂ –∏ –ø–µ—Ä–µ—Ö–æ–¥—É –∫ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏. –ï–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–π–æ–Ω–µ 4210-4240 —Ä—É–±.\\n\\n‚Ä¢–ü—Ä–∏ —ç—Ç–æ–º –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥, —Ü–µ–ª—å—é –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Ä–æ–≤–µ–Ω—å 4520 —Ä—É–±., –æ—Å—Ç–∞–µ—Ç—Å—è –∞–∫—Ç—É–∞–ª–µ–Ω. –ï—Å–ª–∏ —ç–∫—Å—Ç—Ä–∞–ø–æ–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–º–ø—ã —Ä–æ—Å—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–Ω–µ–π –≤–ø–µ—Ä–µ–¥, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –º–æ–∂–µ—Ç –≤–æ–π—Ç–∏ –≤ –∑–æ–Ω—É 4430‚Äì4520 —Ä—É–±. —É–∂–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ.\\n\\n‚Ä¢–û—Ç—á–µ—Ç—ã –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –Ω–µ—Ñ—Ç—è–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –ø–æ–∑–≤–æ–ª—è—é—Ç –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å, —á—Ç–æ II –ø–æ–ª—É–≥–æ–¥–∏–µ –¥–ª—è –õ–£–ö–û–ô–õ–∞ –±—ã–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–ª—å–Ω—ã–º. –≠—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –µ—Å—Ç—å –Ω–∞–¥–µ–∂–¥–∞ –Ω–∞ —Ö–æ—Ä–æ—à–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∏–≤–∏–¥–µ–Ω–¥—ã –∑–∞ 2022 –≥. –≠—Ç–æ—Ç —Ñ–∞–∫—Ç–æ—Ä –º–æ–∂–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å –∫ –∞–∫—Ü–∏—è–º –∫–æ–º–ø–∞–Ω–∏–∏.\\n\\n‚Ä¢–û–¥–Ω–∞–∫–æ –ø–æ–∫—É–ø–∫–∏ —Å–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –ø–æ–≤—ã—à–µ–Ω–Ω—ã–º —É—Ä–æ–≤–Ω–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å–µ–∫—Ç–æ—Ä–µ. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –∫–æ–º–ø–∞–Ω–∏—è –º–æ–≥–ª–∞ —Å–∏–ª—å–Ω–µ–µ –¥—Ä—É–≥–∏—Ö –ø–æ—Å—Ç—Ä–∞–¥–∞—Ç—å –∏–∑-–∑–∞ –≤–Ω–µ—à–Ω–∏—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π, —á—Ç–æ –º–æ–∂–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ —Å–∫–∞–∑–∞—Ç—å—Å—è –Ω–∞ –±—É–¥—É—â–∏—Ö –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç–∞—Ö.\\n\\n–í–Ω–µ—à–Ω–∏–π —Ñ–æ–Ω:\\n–í–Ω–µ—à–Ω–∏–π —Ñ–æ–Ω —Å —É—Ç—Ä–∞ —Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è —Å–º–µ—à–∞–Ω–Ω—ã–π. –ê–∑–∏–∞—Ç—Å–∫–∏–µ –∏–Ω–¥–µ–∫—Å—ã —Ç–æ—Ä–≥—É—é—Ç—Å—è —Ä–∞–∑–Ω–æ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ. –§—å—é—á–µ—Ä—Å –Ω–∞ S&P 500 –ø–∞–¥–∞–µ—Ç –Ω–∞ 0,04%. –ù–µ—Ñ—Ç—å Brent —Å–µ–≥–æ–¥–Ω—è –≤ –º–∏–Ω—É—Å–µ –Ω–∞ 0,4%.\\n\\n–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∞\\n\\n‚Ä¢–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –∞–∫—Ü–∏–∏ —É–º–µ—Ä–µ–Ω–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π. –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ñ–æ—Ä–º–∏—Ä—É—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—É—é –∫–∞—Ä—Ç–∏–Ω—É. –≠–º–±–∞—Ä–≥–æ –Ω–∞ –Ω–µ—Ñ—Ç—å –∏ –Ω–µ—Ñ—Ç–µ–ø—Ä–æ–¥—É–∫—Ç—ã –≤ –ï–° –Ω–µ—Å–µ—Ç –æ—â—É—Ç–∏–º—ã–µ —Ä–∏—Å–∫–∏ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏, –Ω–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–∞–≤–æ–∫ –º–æ–∂–µ—Ç –ø–æ–∑–≤–æ–ª–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–æ—Å—Ç–æ–π–Ω—ã–µ –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ —Ñ–æ–Ω–µ –≤—ã—Å–æ–∫–∏—Ö –º–∏—Ä–æ–≤—ã—Ö —Ü–µ–Ω –Ω–∞ –Ω–µ—Ñ—Ç—å.\\n\\n‚Ä¢–°–Ω–∏–∑—É –∑–Ω–∞—á–∏–º–æ–π –∑–æ–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≤—ã—Å—Ç—É–ø–∞–µ—Ç –∫–æ—Ä–∏–¥–æ—Ä 3600‚Äì3700 —Ä—É–±. –¶–µ–ª—å—é –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–∏ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ–π –∫–æ–Ω—ä—é–Ω–∫—Ç—É—Ä–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫—Ä—É–≥–ª–∞—è –æ—Ç–º–µ—Ç–∫–∞ 5000 —Ä—É–±.\\nüìç–ò—Å—Ç–æ—á–Ω–∏–∫: –ë–ö–° {$LKOH} \\n\\nüëâ–í —Ä–∞–º–∫–∞—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ [&–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞](    –∞–∫—Ü–∏–∏ –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –≥–¥–µ –º—ã —É–¥–µ—Ä–∂–∏–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç –Ω–µ–¥–µ–ª–∏ –¥–æ –º–µ—Å—è—Ü–∞, –≤ —Ä–µ–¥–∫–∏—Ö —Å–ª—É—á–∞—è—Ö –∏ –±–æ–ª–µ–µ. \\n\\nüëâ–í —Ä–∞–º–∫–∞—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ [&–ì—Ä–æ—à —Ü–µ–Ω–∞. –ù–∞ –ø–µ–Ω—Å–∏—é –≤–Ω—É–∫–∞–º](  –º—ã —É–¥–µ—Ä–∂–∏–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–∏. –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã—Ö –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤. \\n\\nüëâ [&–ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –¥–æ—Å—Ç–æ—è–Ω–∏–µ](   –ú–æ—è –Ω–æ–≤–∞—è, –∑–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –±–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ —Å—ã—Ä—å–µ–≤–æ–π –¥–æ–±—ã—á–µ. \\n–†–æ—Å—Å–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –≤–µ–¥—É—â–µ–µ –º–µ—Å—Ç–æ –≤ –º–∏—Ä–µ –ø–æ –∑–∞–ø–∞—Å–∞–º –Ω–µ—Ñ—Ç–∏, –≥–∞–∑–∞, —É–≥–ª—è. –ù–∞ —ç—Ç–æ–º –º—ã –∏ –±—É–¥–µ–º –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å.\\n\\n‚úÖüëâ–ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ—á–µ–Ω—å –ø–æ–¥–∞—Ä–∫–æ–≤, –ø—Ä–∏–¥—ë—Ç—Å—è –ø–æ –≤–∫—É—Å—É –∫–∞–∂–¥–æ–º—É. –í—ã–±–∏—Ä–∞–π —Å–∞–º)',\n",
       "       '{$MMU3} {$SBER} —É –∫–æ–≥–æ –µ—â–µ –≤–∏—Å—è—Ç —É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–∞—è–≤–∫–∏? –∏ –ø–æ –∫–∞–∫–æ–π —Ü–µ–Ω–µ –æ–Ω–∏ –∏—Å–ø–æ–ª–Ω—è—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ',\n",
       "       '–°–∞–º–æ–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ —á—Ç–æ –º–æ–≥–ª–æ –±—ã—Ç—å ‚Äì —Å–∞–Ω–∫—Ü–∏–∏ –Ω–∞ –ù–ö–¶, –∫–æ—Ç–æ—Ä—ã—Ö –º—ã –Ω–µ —É–≤–∏–¥–µ–ª–∏. –í—Å–µ —ç—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ –æ–∫–∞–∂—É—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∏–Ω–¥–µ–∫—Å IMOEX. –ù–∞ –æ–∂–∏–¥–∞–Ω–∏—è—Ö –º—ã –ø–∞–¥–∞–ª–∏, —Ç–∞–∫ —á—Ç–æ —è –ø—Ä–µ–¥–ø–æ–ª–æ–∂—É —Å–ª–µ–¥—É—é—â–µ–µ: —Ö—É–¥—à–µ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è –º—ã –Ω–µ —É–≤–∏–¥–µ–ª–∏, –ª—é–¥–∏ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ –Ω–∞—á–Ω—É—Ç –æ—Ç–∫—É–ø–∞—Ç—å —Å–≤–æ–∏ —à–æ—Ä—Ç—ã, –∞ –∫—Ç–æ-—Ç–æ —Å–Ω–æ–≤–∞ –Ω–∞–±–∏—Ä–∞—Ç—å –ø–æ–∑–∏—Ü–∏–∏ –≤ –∞–∫—Ü–∏—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–ø–∞–ª–∏ –ø–æ–¥ —Å–∞–Ω–∫—Ü–∏–∏ (–º–Ω–æ–≥–æ–µ –¥–∞—é—Ç –ø–æ —Ö–æ—Ä–æ—à–∏–º —Ü–µ–Ω–∞–º). –õ–∏—á–Ω–æ —è —Å—Ç–∞–≤–ª—é –Ω–∞ —Ä–æ—Å—Ç –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ –≤—ã—à–µ –ø–∞–¥–µ–Ω–∏—è). {$SBER} —É –º–µ–Ω—è —Ñ–∞–≤–æ—Ä–∏—Ç –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ.',\n",
       "       '{$MTLR} –≤–∞–ª–∏—Ç–µ –µ–µ –¥–æ 305, —Ç–∞–º –∑–∞–∫—É–ø–∏–º—Å—è'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified_qwen.processed_posts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:16:57.044691Z",
     "iopub.status.busy": "2025-05-02T18:16:57.044218Z",
     "iopub.status.idle": "2025-05-02T18:20:49.066338Z",
     "shell.execute_reply": "2025-05-02T18:20:49.065222Z",
     "shell.execute_reply.started": "2025-05-02T18:16:57.044667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-14B\" \n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 4-–±–∏—Ç–Ω–æ–π –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ (NF4)\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16, # –¢–∏–ø –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è bfloat16)\n",
    "#     bnb_4bit_quant_type=\"nf4\",           # –¢–∏–ø –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏\n",
    "#     bnb_4bit_use_double_quant=True,     # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–≤–æ–π–Ω—É—é –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏\n",
    "# )\n",
    "\n",
    "# –ò–ª–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 8-–±–∏—Ç–Ω–æ–π –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ (–µ—Å–ª–∏ 4-–±–∏—Ç–Ω–∞—è –¥–∞–µ—Ç –ø–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_8bit=True,\n",
    ")\n",
    "\n",
    "print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –∫–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\", # device_map=\"auto\" —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å bitsandbytes\n",
    "    quantization_config=quantization_config, # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏\n",
    "    trust_remote_code=True \n",
    "    # max_memory –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å, –Ω–æ —Ç–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ª–µ–≥–∫–æ –ø–æ–º–µ—â–∞—Ç—å—Å—è\n",
    ")\n",
    "print(\"–ö–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7310590,
     "sourceId": 11649552,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7312603,
     "sourceId": 11652388,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
